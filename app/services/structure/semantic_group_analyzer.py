"""
Phase 4: è¯­ä¹‰åˆ†ç»„åˆ†æå™¨

å°†Phase 2è¯†åˆ«çš„å¹³é“ºå­—æ®µè½¬æ¢ä¸ºæœ‰ç»“æ„çš„é€»è¾‘åˆ†ç»„
åŸºäºé…ç½®é©±åŠ¨çš„æ™ºèƒ½åŒ¹é…ï¼Œé¿å…ç¡¬ç¼–ç 
"""

import logging
from typing import Dict, List, Any, Optional
from pathlib import Path

from .fuzzy_matcher import FuzzyMatcher

logger = logging.getLogger(__name__)


class SemanticGroupAnalyzer:
    """è¯­ä¹‰åˆ†ç»„åˆ†æå™¨ - Phase 4æ ¸å¿ƒæ¨¡å—"""

    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–è¯­ä¹‰åˆ†ç»„åˆ†æå™¨

        Args:
            config_path: è¯­ä¹‰é…ç½®æ–‡ä»¶è·¯å¾„
        """
        if not config_path:
            config_path = Path(__file__).parent.parent.parent / "config" / "semantic_groups.json"

        self.fuzzy_matcher = FuzzyMatcher(str(config_path))
        logger.info("ğŸ¯ Phase 4è¯­ä¹‰åˆ†ç»„åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def analyze_structure(self, phase2_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†æPhase 2ç»“æœï¼Œç”Ÿæˆç»“æ„åŒ–åˆ†ç»„

        Args:
            phase2_result: Phase 2çš„åˆ†æç»“æœ

        Returns:
            ç»“æ„åŒ–åˆ†ç»„ç»“æœ
        """
        try:
            logger.info("ğŸ” Phase 4å¼€å§‹ç»“æ„åˆ†æ...")

            # æå–Phase 2çš„å­—æ®µæ•°æ®
            elements_data = phase2_result.get('elements', {})
            fields = elements_data.get('elements_data', [])
            relationships = phase2_result.get('relationships', {})

            if not fields:
                logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å­—æ®µæ•°æ®ï¼Œè·³è¿‡ç»“æ„åˆ†æ")
                return self._create_empty_result()

            logger.info(f"ğŸ“Š å¼€å§‹åˆ†æ {len(fields)} ä¸ªå­—æ®µ")

            # ç¬¬1æ­¥: ä¸ºæ¯ä¸ªå­—æ®µè¿›è¡Œè¯­ä¹‰åŒ¹é…
            matched_fields = self._match_fields_semantically(fields)

            # ç¬¬2æ­¥: æ£€æµ‹å’Œåˆ†ç»„æ•°ç»„å­—æ®µ
            array_analysis = self._analyze_array_patterns(matched_fields)

            # ç¬¬3æ­¥: æ„å»ºé€»è¾‘åˆ†ç»„
            logical_groups = self._build_logical_groups(array_analysis, relationships)

            # ç¬¬4æ­¥: ç”Ÿæˆæœ€ç»ˆç»“æ„æ¨¡æ¿
            structure_template = self._generate_structure_template(logical_groups)

            # ç¬¬5æ­¥: éªŒè¯å’Œä¼˜åŒ–ç»“æ„
            validated_structure = self._validate_and_optimize_structure(structure_template)

            result = {
                'success': True,
                'phase': 'phase4_structure_recognition',
                'input_fields': len(fields),
                'logical_groups': validated_structure['groups'],
                'structure_template': validated_structure['template'],
                'analysis_summary': validated_structure['summary'],
                'ready_for_phase5': True
            }

            logger.info(f"âœ… Phase 4ç»“æ„åˆ†æå®Œæˆ: {len(validated_structure['groups'])}ä¸ªé€»è¾‘åˆ†ç»„")
            return result

        except Exception as e:
            logger.error(f"âŒ Phase 4ç»“æ„åˆ†æå¤±è´¥: {str(e)}", exc_info=True)
            return {
                'success': False,
                'error': f"Phase 4ç»“æ„åˆ†æé”™è¯¯: {str(e)}",
                'phase': 'phase4_structure_recognition_error'
            }

    def _match_fields_semantically(self, fields: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ä¸ºæ¯ä¸ªå­—æ®µè¿›è¡Œè¯­ä¹‰åŒ¹é…

        Args:
            fields: å­—æ®µåˆ—è¡¨

        Returns:
            å¸¦æœ‰è¯­ä¹‰åŒ¹é…ä¿¡æ¯çš„å­—æ®µåˆ—è¡¨
        """
        matched_fields = []

        for field in fields:
            # æå–å­—æ®µä¿¡æ¯
            field_label = self._extract_field_label(field)
            field_name = field.get('name', '') or field.get('selector', '')

            # è¿›è¡Œè¯­ä¹‰åŒ¹é…
            match_result = self.fuzzy_matcher.find_best_match(
                field_label=field_label,
                field_name=field_name
            )

            # ä¿å­˜åŒ¹é…ç»“æœ
            enhanced_field = field.copy()
            if match_result:
                enhanced_field['semantic_match'] = match_result
                logger.info(f"âœ… åŒ¹é…æˆåŠŸ: '{field_label}' â†’ {match_result['group_title']}.{match_result.get('field_type')} (å¾—åˆ†: {match_result['score']:.2f})")
            else:
                enhanced_field['semantic_match'] = None
                logger.info(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…: '{field_label}' (name: {field_name})")

            matched_fields.append(enhanced_field)

        # ç»Ÿè®¡åŒ¹é…ç»“æœ
        matched_count = sum(1 for f in matched_fields if f.get('semantic_match'))
        logger.info(f"ğŸ“Š è¯­ä¹‰åŒ¹é…å®Œæˆ: {matched_count}/{len(fields)} ä¸ªå­—æ®µåŒ¹é…æˆåŠŸ")

        return matched_fields

    def _analyze_array_patterns(self, fields: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†ææ•°ç»„æ¨¡å¼å­—æ®µ

        Args:
            fields: å¸¦æœ‰è¯­ä¹‰åŒ¹é…çš„å­—æ®µåˆ—è¡¨

        Returns:
            æ•°ç»„åˆ†æç»“æœ
        """
        # ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…å™¨çš„æ•°ç»„åˆ†ç»„åŠŸèƒ½
        grouping_result = self.fuzzy_matcher.group_array_fields(fields)

        array_groups = grouping_result['array_groups']
        single_fields = grouping_result['single_fields']

        # åˆ†ææ•°ç»„ç»„çš„è¯­ä¹‰ä¸€è‡´æ€§
        validated_arrays = {}
        for base_name, group_fields in array_groups.items():
            if self._validate_array_semantic_consistency(group_fields):
                validated_arrays[base_name] = {
                    'fields': group_fields,
                    'count': len(group_fields),
                    'base_name': base_name,
                    'is_repeatable': True
                }
                logger.info(f"ğŸ“‹ æ£€æµ‹åˆ°é‡å¤ç»“æ„: {base_name} ({len(group_fields)}ä¸ªå®ä¾‹)")
            else:
                # è¯­ä¹‰ä¸ä¸€è‡´çš„æ•°ç»„ï¼Œæ‹†åˆ†ä¸ºå•ä¸ªå­—æ®µ
                single_fields.extend(group_fields)

        return {
            'array_groups': validated_arrays,
            'single_fields': single_fields,
            'total_arrays': len(validated_arrays)
        }

    def _validate_array_semantic_consistency(self, group_fields: List[Dict[str, Any]]) -> bool:
        """
        éªŒè¯æ•°ç»„å­—æ®µçš„è¯­ä¹‰ä¸€è‡´æ€§

        Args:
            group_fields: æ•°ç»„åˆ†ç»„çš„å­—æ®µåˆ—è¡¨

        Returns:
            æ˜¯å¦è¯­ä¹‰ä¸€è‡´
        """
        if len(group_fields) < 2:
            return False

        # æ£€æŸ¥è¯­ä¹‰åŒ¹é…çš„ä¸€è‡´æ€§
        semantic_groups = set()
        for field in group_fields:
            match = field.get('semantic_match')
            if match:
                semantic_groups.add(match['group_id'])

        # å¦‚æœæ‰€æœ‰å­—æ®µéƒ½å±äºåŒä¸€ä¸ªè¯­ä¹‰åˆ†ç»„ï¼Œè®¤ä¸ºæ˜¯ä¸€è‡´çš„
        return len(semantic_groups) <= 1

    def _build_logical_groups(self, array_analysis: Dict[str, Any], relationships: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        æ„å»ºé€»è¾‘åˆ†ç»„

        Args:
            array_analysis: æ•°ç»„åˆ†æç»“æœ
            relationships: å­—æ®µå…³ç³»ä¿¡æ¯

        Returns:
            é€»è¾‘åˆ†ç»„åˆ—è¡¨
        """
        logical_groups = []

        # å¤„ç†å•ä¸ªå­—æ®µ - æŒ‰è¯­ä¹‰åˆ†ç»„
        single_fields = array_analysis['single_fields']
        single_groups = self._group_single_fields_by_semantics(single_fields)

        # å¤„ç†æ•°ç»„å­—æ®µ - æ¯ä¸ªæ•°ç»„æˆä¸ºç‹¬ç«‹åˆ†ç»„
        array_groups = array_analysis['array_groups']
        array_logical_groups = self._convert_arrays_to_logical_groups(array_groups)

        # åˆå¹¶æ‰€æœ‰åˆ†ç»„
        all_groups = single_groups + array_logical_groups

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        all_groups.sort(key=lambda x: x.get('priority', 999))

        return all_groups

    def _group_single_fields_by_semantics(self, fields: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å°†å•ä¸ªå­—æ®µæŒ‰è¯­ä¹‰åˆ†ç»„

        Args:
            fields: å•ä¸ªå­—æ®µåˆ—è¡¨

        Returns:
            è¯­ä¹‰åˆ†ç»„åˆ—è¡¨
        """
        semantic_groups = {}
        unmatched_fields = []

        for field in fields:
            match = field.get('semantic_match')
            if match:
                group_id = match['group_id']
                if group_id not in semantic_groups:
                    semantic_groups[group_id] = {
                        'group_id': group_id,
                        'title': match['group_title'],
                        'priority': match['priority'],
                        'is_repeatable': False,
                        'fields': [],
                        'field_types': set()
                    }

                semantic_groups[group_id]['fields'].append(field)
                semantic_groups[group_id]['field_types'].add(match.get('field_type', 'unknown'))
            else:
                unmatched_fields.append(field)

        # è½¬æ¢ä¸ºåˆ—è¡¨
        groups = list(semantic_groups.values())

        # å¤„ç†æœªåŒ¹é…å­—æ®µ
        if unmatched_fields:
            groups.append({
                'group_id': 'unmatched',
                'title': 'å…¶ä»–å­—æ®µ',
                'priority': 999,
                'is_repeatable': False,
                'fields': unmatched_fields,
                'field_types': set(['unknown'])
            })

        return groups

    def _convert_arrays_to_logical_groups(self, array_groups: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        å°†æ•°ç»„è½¬æ¢ä¸ºé€»è¾‘åˆ†ç»„

        Args:
            array_groups: æ•°ç»„åˆ†ç»„

        Returns:
            é€»è¾‘åˆ†ç»„åˆ—è¡¨
        """
        logical_groups = []

        for base_name, array_info in array_groups.items():
            fields = array_info['fields']

            # è·å–ç¬¬ä¸€ä¸ªå­—æ®µçš„è¯­ä¹‰åŒ¹é…ä¿¡æ¯ä½œä¸ºç»„çš„è¯­ä¹‰
            first_field = fields[0] if fields else {}
            semantic_match = first_field.get('semantic_match') or {}

            # å®‰å…¨åœ°è·å–è¯­ä¹‰ä¿¡æ¯ï¼Œæä¾›é»˜è®¤å€¼
            group_title = semantic_match.get('group_title', f"{base_name}åˆ—è¡¨")
            priority = semantic_match.get('priority', 500)
            field_type = semantic_match.get('field_type', 'unknown')

            group = {
                'group_id': f"array_{base_name}",
                'title': group_title,
                'priority': priority,
                'is_repeatable': True,
                'array_base_name': base_name,
                'array_count': len(fields),
                'fields': fields,
                'field_types': set([field_type])
            }

            logical_groups.append(group)

        return logical_groups

    def _generate_structure_template(self, logical_groups: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»“æ„åŒ–æ¨¡æ¿

        Args:
            logical_groups: é€»è¾‘åˆ†ç»„åˆ—è¡¨

        Returns:
            ç»“æ„åŒ–æ¨¡æ¿
        """
        template = {
            'groups': [],
            'metadata': {
                'total_groups': len(logical_groups),
                'repeatable_groups': 0,
                'single_groups': 0,
                'total_fields': 0
            }
        }

        for group in logical_groups:
            group_template = {
                'id': group['group_id'],
                'title': group['title'],
                'priority': group['priority'],
                'is_repeatable': group['is_repeatable'],
                'field_count': len(group['fields']),
                'fields': []
            }

            # å¤„ç†å­—æ®µ
            for field in group['fields']:
                field_template = {
                    'selector': field.get('selector', ''),
                    'type': field.get('type', 'unknown'),
                    'label': self._extract_field_label(field),
                    'required': field.get('required', False),
                    'bbox': field.get('bbox', {}),
                    'semantic_type': None
                }

                # æ·»åŠ è¯­ä¹‰ä¿¡æ¯
                semantic_match = field.get('semantic_match')
                if semantic_match:
                    field_template['semantic_type'] = semantic_match.get('field_type')
                    field_template['semantic_group'] = semantic_match.get('group_id')
                    field_template['match_score'] = semantic_match.get('score', 0)

                # æ·»åŠ æ•°ç»„ä¿¡æ¯
                array_info = field.get('array_info')
                if array_info and array_info.get('is_array'):
                    field_template['array_index'] = array_info.get('index', 0)
                    field_template['array_base_name'] = array_info.get('base_name', '')

                group_template['fields'].append(field_template)

            template['groups'].append(group_template)

            # æ›´æ–°å…ƒæ•°æ®
            if group['is_repeatable']:
                template['metadata']['repeatable_groups'] += 1
            else:
                template['metadata']['single_groups'] += 1

            template['metadata']['total_fields'] += len(group['fields'])

        return template

    def _validate_and_optimize_structure(self, structure_template: Dict[str, Any]) -> Dict[str, Any]:
        """
        éªŒè¯å’Œä¼˜åŒ–ç»“æ„

        Args:
            structure_template: ç»“æ„æ¨¡æ¿

        Returns:
            éªŒè¯å’Œä¼˜åŒ–åçš„ç»“æ„
        """
        groups = structure_template['groups']

        # éªŒè¯åˆ†ç»„è´¨é‡
        quality_metrics = self._calculate_structure_quality(groups)

        # ç”Ÿæˆåˆ†ææ‘˜è¦
        summary = {
            'structure_quality': quality_metrics,
            'group_distribution': self._analyze_group_distribution(groups),
            'field_coverage': self._analyze_field_coverage(groups),
            'recommendations': self._generate_recommendations(quality_metrics, groups)
        }

        return {
            'groups': groups,
            'template': structure_template,
            'summary': summary
        }

    def _calculate_structure_quality(self, groups: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        è®¡ç®—ç»“æ„è´¨é‡æŒ‡æ ‡

        Args:
            groups: åˆ†ç»„åˆ—è¡¨

        Returns:
            è´¨é‡æŒ‡æ ‡
        """
        total_fields = sum(group['field_count'] for group in groups)
        matched_fields = 0
        high_confidence_matches = 0

        for group in groups:
            for field in group['fields']:
                if field.get('semantic_type'):
                    matched_fields += 1
                    if field.get('match_score', 0) > 0.8:
                        high_confidence_matches += 1

        return {
            'total_fields': total_fields,
            'semantic_match_rate': matched_fields / total_fields if total_fields > 0 else 0,
            'high_confidence_rate': high_confidence_matches / total_fields if total_fields > 0 else 0,
            'group_count': len(groups),
            'average_group_size': total_fields / len(groups) if groups else 0
        }

    def _analyze_group_distribution(self, groups: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†æåˆ†ç»„åˆ†å¸ƒ

        Args:
            groups: åˆ†ç»„åˆ—è¡¨

        Returns:
            åˆ†å¸ƒåˆ†æç»“æœ
        """
        group_sizes = [group['field_count'] for group in groups]
        repeatable_count = sum(1 for group in groups if group['is_repeatable'])

        return {
            'total_groups': len(groups),
            'repeatable_groups': repeatable_count,
            'single_groups': len(groups) - repeatable_count,
            'min_group_size': min(group_sizes) if group_sizes else 0,
            'max_group_size': max(group_sizes) if group_sizes else 0,
            'average_group_size': sum(group_sizes) / len(group_sizes) if group_sizes else 0
        }

    def _analyze_field_coverage(self, groups: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†æå­—æ®µè¦†ç›–æƒ…å†µ

        Args:
            groups: åˆ†ç»„åˆ—è¡¨

        Returns:
            è¦†ç›–åˆ†æç»“æœ
        """
        semantic_types = set()
        group_types = set()

        for group in groups:
            group_types.add(group['id'])
            for field in group['fields']:
                if field.get('semantic_type'):
                    semantic_types.add(field['semantic_type'])

        return {
            'unique_semantic_types': len(semantic_types),
            'unique_group_types': len(group_types),
            'semantic_types': list(semantic_types),
            'group_types': list(group_types)
        }

    def _generate_recommendations(self, quality_metrics: Dict[str, Any], groups: List[Dict[str, Any]]) -> List[str]:
        """
        ç”Ÿæˆä¼˜åŒ–å»ºè®®

        Args:
            quality_metrics: è´¨é‡æŒ‡æ ‡
            groups: åˆ†ç»„åˆ—è¡¨

        Returns:
            å»ºè®®åˆ—è¡¨
        """
        recommendations = []

        # åŸºäºè¯­ä¹‰åŒ¹é…ç‡çš„å»ºè®®
        match_rate = quality_metrics['semantic_match_rate']
        if match_rate < 0.8:
            recommendations.append(f"è¯­ä¹‰åŒ¹é…ç‡åä½ ({match_rate:.1%})ï¼Œå»ºè®®æ‰©å±•è¯­ä¹‰é…ç½®")

        # åŸºäºåˆ†ç»„æ•°é‡çš„å»ºè®®
        group_count = quality_metrics['group_count']
        if group_count > 8:
            recommendations.append("åˆ†ç»„æ•°é‡è¾ƒå¤šï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥åˆå¹¶ç›¸å…³åˆ†ç»„")
        elif group_count < 3:
            recommendations.append("åˆ†ç»„æ•°é‡è¾ƒå°‘ï¼Œå¯èƒ½å­˜åœ¨è¿‡åº¦åˆå¹¶")

        # åŸºäºåˆ†ç»„å¤§å°çš„å»ºè®®
        avg_size = quality_metrics['average_group_size']
        if avg_size > 10:
            recommendations.append("å¹³å‡åˆ†ç»„å¤§å°è¾ƒå¤§ï¼Œè€ƒè™‘è¿›ä¸€æ­¥ç»†åˆ†")
        elif avg_size < 2:
            recommendations.append("å¹³å‡åˆ†ç»„å¤§å°è¾ƒå°ï¼Œå¯èƒ½è¿‡åº¦ç»†åˆ†")

        return recommendations

    def _extract_field_label(self, field: Dict[str, Any]) -> str:
        """
        æå–å­—æ®µæ ‡ç­¾æ–‡æœ¬ - ä¼˜åŒ–ç‰ˆ

        Args:
            field: å­—æ®µæ•°æ®

        Returns:
            å­—æ®µæ ‡ç­¾
        """
        # ä»å…³è”æ ‡ç­¾ä¸­æå– - ä½¿ç”¨ç¬¬ä¸€ä¸ªï¼ˆä¼˜å…ˆçº§æœ€é«˜çš„ï¼‰æ ‡ç­¾
        labels = field.get('associated_labels', [])
        if labels:
            # è·å–ç¬¬ä¸€ä¸ªæœ‰æ•ˆæ ‡ç­¾ï¼ˆå·²ç»æŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
            for label in labels:
                label_text = label.get('text', '').strip()
                if label_text and label_text not in ['unknown', 'input', 'text']:
                    return label_text

        # fallbackåˆ°å…¶ä»–å±æ€§
        fallback_value = (field.get('placeholder', '') or
                         field.get('title', '') or
                         field.get('name', '') or
                         field.get('id', '') or
                         'unknown').strip()

        return fallback_value

    def _create_empty_result(self) -> Dict[str, Any]:
        """åˆ›å»ºç©ºç»“æœ"""
        return {
            'success': True,
            'phase': 'phase4_structure_recognition',
            'input_fields': 0,
            'logical_groups': [],
            'structure_template': {'groups': [], 'metadata': {}},
            'analysis_summary': {},
            'ready_for_phase5': False,
            'warning': 'æ²¡æœ‰å­—æ®µæ•°æ®å¯åˆ†æ'
        }
