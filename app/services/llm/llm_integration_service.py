"""
Phase 5: LLMé›†æˆä¸»æœåŠ¡

æ•´åˆæ•°æ®æ ¼å¼è½¬æ¢ã€æ™ºèƒ½æç¤ºè¯ç”Ÿæˆã€ç»“æœéªŒè¯ç­‰åŠŸèƒ½
æä¾›ä»Phase 4ç»“æ„åŒ–æ•°æ®åˆ°æœ€ç»ˆåŒ¹é…ç»“æœçš„å®Œæ•´æµç¨‹
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Any, Optional

from .data_formatter import LLMDataFormatter
from .prompt_builder import StructuredPromptBuilder
from ..validation.result_validator import ResultValidator
from ..ai_service import AIService

logger = logging.getLogger(__name__)


class LLMIntegrationService:
    """LLMé›†æˆæœåŠ¡ - Phase 5ä¸»æœåŠ¡"""

    def __init__(self, ai_service=None):
        """
        åˆå§‹åŒ–LLMé›†æˆæœåŠ¡

        Args:
            ai_service: AIæœåŠ¡å®ä¾‹ï¼ˆç”¨äºè°ƒç”¨å¤§æ¨¡å‹ï¼‰
        """
        self.data_formatter = LLMDataFormatter()
        self.prompt_builder = StructuredPromptBuilder()
        self.result_validator = ResultValidator()
        self.ai_service = ai_service

        logger.info("ğŸ¤– Phase 5 LLMé›†æˆæœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    async def process_structured_matching(self,
                                        phase4_result: Dict[str, Any],
                                        resume_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†ç»“æ„åŒ–åŒ¹é… - Phase 5ä¸»å…¥å£

        Args:
            phase4_result: Phase 4çš„ç»“æ„åŒ–åˆ†æç»“æœ
            resume_data: ç”¨æˆ·ç®€å†æ•°æ®

        Returns:
            å®Œæ•´çš„åŒ¹é…ç»“æœï¼ŒåŒ…å«éªŒè¯ä¿¡æ¯
        """
        start_time = time.time()

        try:
            logger.info("ğŸš€ Phase 5å¼€å§‹å¤„ç†ç»“æ„åŒ–åŒ¹é…...")

            # Step 1: æ•°æ®æ ¼å¼è½¬æ¢
            logger.info("ğŸ“Š Step 1: è½¬æ¢æ•°æ®æ ¼å¼...")
            llm_data = self.data_formatter.format_for_llm(phase4_result)

            if not llm_data.get('form_structure', {}).get('groups'):
                logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„è¡¨å•åˆ†ç»„æ•°æ®")
                return self._create_empty_result("æ²¡æœ‰æœ‰æ•ˆçš„è¡¨å•åˆ†ç»„æ•°æ®")

            # Step 2: ç”Ÿæˆæ™ºèƒ½æç¤ºè¯
            logger.info("ğŸ’¬ Step 2: ç”Ÿæˆæ™ºèƒ½æç¤ºè¯...")
            structure_summary = self.data_formatter.extract_structure_summary(llm_data)
            prompt = self.prompt_builder.build_matching_prompt(
                form_data=llm_data,
                resume_data=resume_data,
                structure_summary=structure_summary
            )

            # Step 3: è°ƒç”¨å¤§æ¨¡å‹è¿›è¡ŒåŒ¹é…
            logger.info("ğŸ§  Step 3: è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œå­—æ®µåŒ¹é…...")
            if not self.ai_service:
                logger.warning("âš ï¸ AIæœåŠ¡æœªé…ç½®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ")
                llm_response = self._simulate_llm_response(llm_data, resume_data)
            else:
                llm_response = await self.ai_service.analyze_with_prompt(prompt)

            # Step 4: è§£æå¤§æ¨¡å‹å“åº”
            logger.info("ğŸ”„ Step 4: è§£æå¤§æ¨¡å‹å“åº”...")
            matching_results = self._parse_llm_response(llm_response)

            # Step 5: éªŒè¯åŒ¹é…ç»“æœ
            logger.info("ğŸ” Step 5: éªŒè¯åŒ¹é…ç»“æœ...")
            validation_result = self.result_validator.validate_matching_results(
                matching_results=matching_results,
                form_data=llm_data
            )

            # Step 6: æ„å»ºæœ€ç»ˆç»“æœ
            processing_time = time.time() - start_time
            final_result = self._build_final_result(
                phase4_result=phase4_result,
                llm_data=llm_data,
                matching_results=matching_results,
                validation_result=validation_result,
                processing_time=processing_time,
                structure_summary=structure_summary
            )

            logger.info(f"âœ… Phase 5å¤„ç†å®Œæˆ: {len(matching_results)}ä¸ªå­—æ®µåŒ¹é…, ç”¨æ—¶{processing_time:.2f}ç§’")
            return final_result

        except Exception as e:
            logger.error(f"âŒ Phase 5å¤„ç†å¤±è´¥: {str(e)}", exc_info=True)
            return self._create_error_result(str(e))

    def _simulate_llm_response(self, llm_data: Dict[str, Any], resume_data: Dict[str, Any]) -> str:
        """
        æ¨¡æ‹Ÿå¤§æ¨¡å‹å“åº”ï¼ˆç”¨äºæµ‹è¯•ï¼‰

        Args:
            llm_data: æ ¼å¼åŒ–åçš„è¡¨å•æ•°æ®
            resume_data: ç®€å†æ•°æ®

        Returns:
            æ¨¡æ‹Ÿçš„LLMå“åº”
        """
        logger.info("ğŸ­ ä½¿ç”¨æ¨¡æ‹ŸLLMå“åº”è¿›è¡Œæµ‹è¯•")

        mock_results = []

        # ç®€å•çš„æ¨¡æ‹ŸåŒ¹é…é€»è¾‘
        resume_name = resume_data.get('basic_info', {}).get('name', 'å¼ ä¸‰')
        resume_phone = resume_data.get('basic_info', {}).get('phone', '13800138000')
        resume_email = resume_data.get('basic_info', {}).get('email', 'test@example.com')

        for group in llm_data.get('form_structure', {}).get('groups', []):
            for field in group.get('fields', []):
                label = field.get('label', '').lower()
                selector = field.get('selector', '')

                value = None
                confidence = 0.8
                reasoning = "æ¨¡æ‹ŸåŒ¹é…"

                # åŸºæœ¬ä¿¡æ¯åŒ¹é…
                if 'å§“å' in label or 'name' in label:
                    value = resume_name
                    confidence = 0.95
                    reasoning = "åŒ¹é…ç®€å†å§“åå­—æ®µ"
                elif 'æ‰‹æœº' in label or 'phone' in label or 'ç”µè¯' in label:
                    value = resume_phone
                    confidence = 0.9
                    reasoning = "åŒ¹é…ç®€å†æ‰‹æœºå·å­—æ®µ"
                elif 'é‚®ç®±' in label or 'email' in label:
                    value = resume_email
                    confidence = 0.9
                    reasoning = "åŒ¹é…ç®€å†é‚®ç®±å­—æ®µ"
                elif 'å­¦æ ¡' in label or 'é™¢æ ¡' in label:
                    value = "æ¸…åå¤§å­¦"
                    confidence = 0.85
                    reasoning = "åŒ¹é…æ•™è‚²ç»å†å­¦æ ¡"
                elif 'ä¸“ä¸š' in label:
                    value = "è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯"
                    confidence = 0.85
                    reasoning = "åŒ¹é…æ•™è‚²ç»å†ä¸“ä¸š"

                if value:
                    mock_results.append({
                        "selector": selector,
                        "value": value,
                        "confidence": confidence,
                        "reasoning": reasoning
                    })

        return json.dumps(mock_results, ensure_ascii=False, indent=2)

    def _parse_llm_response(self, llm_response: str) -> List[Dict[str, Any]]:
        """
        è§£æå¤§æ¨¡å‹å“åº”

        Args:
            llm_response: å¤§æ¨¡å‹çš„å“åº”æ–‡æœ¬

        Returns:
            è§£æåçš„åŒ¹é…ç»“æœåˆ—è¡¨
        """
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            if llm_response.strip().startswith('['):
                return json.loads(llm_response)

            # å°è¯•ä»æ–‡æœ¬ä¸­æå–JSON
            import re
            json_match = re.search(r'\[.*\]', llm_response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())

            # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›ç©ºåˆ—è¡¨
            logger.warning("âš ï¸ æ— æ³•è§£æå¤§æ¨¡å‹å“åº”ï¼Œè¿”å›ç©ºç»“æœ")
            return []

        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
            return []

    def _build_final_result(self,
                          phase4_result: Dict[str, Any],
                          llm_data: Dict[str, Any],
                          matching_results: List[Dict[str, Any]],
                          validation_result: Dict[str, Any],
                          processing_time: float,
                          structure_summary: str) -> Dict[str, Any]:
        """
        æ„å»ºæœ€ç»ˆç»“æœ

        Args:
            phase4_result: Phase 4ç»“æœ
            llm_data: æ ¼å¼åŒ–åçš„æ•°æ®
            matching_results: åŒ¹é…ç»“æœ
            validation_result: éªŒè¯ç»“æœ
            processing_time: å¤„ç†æ—¶é—´
            structure_summary: ç»“æ„æ‘˜è¦

        Returns:
            æœ€ç»ˆç»“æœ
        """
        return {
            'success': True,
            'phase': 'phase5_llm_integration',
            'processing_time': processing_time,

            # æ ¸å¿ƒç»“æœ
            'matching_results': matching_results,
            'validation_result': validation_result,

            # æ•°æ®ç»Ÿè®¡
            'statistics': {
                'input_groups': len(llm_data.get('form_structure', {}).get('groups', [])),
                'input_fields': self.data_formatter.get_total_field_count(llm_data),
                'matched_fields': len(matching_results),
                'valid_matches': validation_result.get('statistics', {}).get('valid_fields', 0),
                'match_rate': len(matching_results) / max(self.data_formatter.get_total_field_count(llm_data), 1),
                'validation_score': validation_result.get('overall_score', 0)
            },

            # è´¨é‡è¯„ä¼°
            'quality_assessment': {
                'overall_quality': self._assess_overall_quality(validation_result, len(matching_results)),
                'structure_quality': phase4_result.get('phase4_quality', {}),
                'matching_quality': validation_result.get('overall_score', 0),
                'recommendations': validation_result.get('suggestions', [])
            },

            # å…ƒæ•°æ®
            'metadata': {
                'structure_summary': structure_summary,
                'complexity': self.prompt_builder.estimate_complexity(llm_data),
                'repeatable_groups': len(self.data_formatter.get_repeatable_groups(llm_data)),
                'phase4_source': {
                    'total_logical_groups': len(phase4_result.get('logical_groups', [])),
                    'phase4_quality_level': phase4_result.get('phase4_quality', {}).get('level', 'unknown')
                }
            },

            # è°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            'debug_info': {
                'llm_input_groups': len(llm_data.get('form_structure', {}).get('groups', [])),
                'validation_issues': len(validation_result.get('issues', [])),
                'has_array_fields': any(
                    field.get('array_index') is not None
                    for group in llm_data.get('form_structure', {}).get('groups', [])
                    for field in group.get('fields', [])
                )
            }
        }

    def _assess_overall_quality(self, validation_result: Dict[str, Any], match_count: int) -> str:
        """è¯„ä¼°æ€»ä½“è´¨é‡"""
        validation_score = validation_result.get('overall_score', 0)
        error_count = len(validation_result.get('issues', []))

        if validation_score >= 0.9 and error_count == 0:
            return 'excellent'
        elif validation_score >= 0.8 and error_count <= 1:
            return 'good'
        elif validation_score >= 0.6 and error_count <= 3:
            return 'fair'
        else:
            return 'poor'

    def _create_empty_result(self, message: str) -> Dict[str, Any]:
        """åˆ›å»ºç©ºç»“æœ"""
        return {
            'success': True,
            'phase': 'phase5_llm_integration',
            'processing_time': 0,
            'matching_results': [],
            'validation_result': {
                'is_valid': True,
                'overall_score': 0,
                'issues': [message],
                'suggestions': []
            },
            'statistics': {
                'input_groups': 0,
                'input_fields': 0,
                'matched_fields': 0,
                'valid_matches': 0,
                'match_rate': 0,
                'validation_score': 0
            },
            'quality_assessment': {
                'overall_quality': 'poor',
                'recommendations': [message]
            }
        }

    def _create_error_result(self, error_message: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return {
            'success': False,
            'error': error_message,
            'phase': 'phase5_llm_integration_error',
            'processing_time': 0,
            'matching_results': [],
            'validation_result': {
                'is_valid': False,
                'overall_score': 0,
                'issues': [f"å¤„ç†é”™è¯¯: {error_message}"],
                'suggestions': ['å»ºè®®é‡æ–°åˆ†æè¡¨å•ç»“æ„']
            }
        }

    async def validate_and_optimize_results(self,
                                          matching_results: List[Dict[str, Any]],
                                          form_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å•ç‹¬çš„ç»“æœéªŒè¯å’Œä¼˜åŒ–æ¥å£

        Args:
            matching_results: åŒ¹é…ç»“æœ
            form_data: è¡¨å•æ•°æ®

        Returns:
            éªŒè¯å’Œä¼˜åŒ–ç»“æœ
        """
        try:
            logger.info("ğŸ” å¼€å§‹ç‹¬ç«‹çš„ç»“æœéªŒè¯...")

            # éªŒè¯ç»“æœ
            validation_result = self.result_validator.validate_matching_results(
                matching_results=matching_results,
                form_data=form_data
            )

            # æ£€æµ‹ä¸ä¸€è‡´æ€§
            inconsistencies = self.result_validator.detect_inconsistencies(matching_results)

            # ç”Ÿæˆä¿®æ­£å»ºè®®
            corrections = self.result_validator.suggest_corrections(inconsistencies)

            return {
                'validation': validation_result,
                'inconsistencies': inconsistencies,
                'corrections': corrections,
                'optimization_suggestions': self._generate_optimization_suggestions(validation_result)
            }

        except Exception as e:
            logger.error(f"âŒ ç‹¬ç«‹éªŒè¯å¤±è´¥: {str(e)}")
            return {
                'validation': {'is_valid': False, 'error': str(e)},
                'inconsistencies': [],
                'corrections': [],
                'optimization_suggestions': []
            }

    def _generate_optimization_suggestions(self, validation_result: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []

        score = validation_result.get('overall_score', 0)
        issues_count = len(validation_result.get('issues', []))

        if score < 0.7:
            suggestions.append("è€ƒè™‘ä¼˜åŒ–Phase 4çš„ç»“æ„è¯†åˆ«ç²¾åº¦")

        if issues_count > 5:
            suggestions.append("å»ºè®®æ£€æŸ¥å­—æ®µæ ‡ç­¾çš„è¯­ä¹‰æ¸…æ™°åº¦")

        return suggestions


# å…¨å±€æœåŠ¡å®ä¾‹ - æ³¨å…¥AIæœåŠ¡
llm_integration_service = LLMIntegrationService(ai_service=AIService)
