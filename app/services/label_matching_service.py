"""
æ™ºèƒ½æ ‡ç­¾åŒ¹é…æœåŠ¡ - æ–°æ–¹æ¡ˆPhase 4
è´Ÿè´£å°†è§†è§‰å¤§æ¨¡å‹è¯†åˆ«çš„å­—æ®µä¸è¡¨å•å­—æ®µè¿›è¡Œæ™ºèƒ½åŒ¹é…

åŒ¹é…ç­–ç•¥ï¼š
1. ç²¾ç¡®åŒ¹é…
2. åŒä¹‰è¯åŒ¹é…
3. æ¨¡ç³ŠåŒ¹é…
4. è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…
"""

import logging
import re
from typing import Dict, List, Any, Tuple, Optional
from difflib import SequenceMatcher
import jieba

logger = logging.getLogger(__name__)


class LabelMatchingService:
    """æ™ºèƒ½æ ‡ç­¾åŒ¹é…æœåŠ¡"""

    def __init__(self):
        """åˆå§‹åŒ–æ ‡ç­¾åŒ¹é…æœåŠ¡"""
        # åŒä¹‰è¯æ˜ å°„è¡¨
        self.synonym_mapping = {
            # åŸºæœ¬ä¿¡æ¯
            "å§“å": ["åå­—", "çœŸå®å§“å", "ç”¨æˆ·å§“å", "ç”³è¯·äººå§“å", "full_name", "name"],
            "æ€§åˆ«": ["gender", "sex"],
            "å¹´é¾„": ["age"],
            "èº«ä»½è¯å·": ["èº«ä»½è¯", "èº«ä»½è¯å·ç ", "è¯ä»¶å·", "è¯ä»¶å·ç ", "id_card", "id_number"],
            "æ‰‹æœºå·": ["ç”µè¯", "æ‰‹æœº", "ç§»åŠ¨ç”µè¯", "è”ç³»ç”µè¯", "phone", "mobile", "telephone"],
            "é‚®ç®±": ["ç”µå­é‚®ç®±", "ç”µå­é‚®ä»¶", "email", "e-mail", "é‚®ä»¶åœ°å€"],
            "åœ°å€": ["è”ç³»åœ°å€", "ç°ä½å€", "å®¶åº­ä½å€", "address", "location"],

            # æ•™è‚²ä¿¡æ¯
            "æ¯•ä¸šé™¢æ ¡": ["å­¦æ ¡", "æ¯•ä¸šå­¦æ ¡", "å°±è¯»é™¢æ ¡", "university", "school", "college"],
            "ä¸“ä¸š": ["æ‰€å­¦ä¸“ä¸š", "ä¸“ä¸šåç§°", "major"],
            "å­¦å†": ["å­¦å†å±‚æ¬¡", "æœ€é«˜å­¦å†", "æ•™è‚²ç¨‹åº¦", "degree", "education"],
            "å­¦ä½": ["å­¦ä½ç±»å‹", "degree"],
            "æ¯•ä¸šæ—¶é—´": ["æ¯•ä¸šå¹´ä»½", "æ¯•ä¸šæ—¥æœŸ", "graduation_time"],
            "å…¥å­¦æ—¶é—´": ["å…¥å­¦æ—¥æœŸ", "å¼€å§‹æ—¶é—´"],
            "å­¦å·": ["student_id", "student_number"],
            "GPA": ["ç»©ç‚¹", "å¹³å‡åˆ†", "æˆç»©"],

            # å·¥ä½œä¿¡æ¯
            "å…¬å¸": ["å·¥ä½œå•ä½", "å°±èŒå…¬å¸", "å•ä½åç§°", "company"],
            "èŒä½": ["å²—ä½", "èŒåŠ¡", "å·¥ä½œå²—ä½", "position", "title", "job"],
            "å·¥ä½œå¹´é™": ["å·¥ä½œç»éªŒ", "ä»ä¸šå¹´é™", "experience_years"],
            "è–ªèµ„": ["å·¥èµ„", "è–ªé…¬", "æœŸæœ›è–ªèµ„", "salary", "wage"],
            "åˆ°å²—æ—¶é—´": ["å…¥èŒæ—¶é—´", "å¯åˆ°å²—æ—¶é—´", "å¼€å§‹å·¥ä½œæ—¶é—´"],

            # å…¶ä»–
            "ç®€å†": ["ä¸ªäººç®€å†", "cv", "resume"],
            "ç…§ç‰‡": ["å¤´åƒ", "è¯ä»¶ç…§", "ä¸ªäººç…§ç‰‡", "photo", "avatar"],
            "å¤‡æ³¨": ["å…¶ä»–", "è¡¥å……è¯´æ˜", "additional_info", "remark"],
            "æŠ€èƒ½": ["ä¸“ä¸šæŠ€èƒ½", "æŠ€èƒ½ç‰¹é•¿", "skills"],
            "è¯ä¹¦": ["èµ„æ ¼è¯ä¹¦", "è¯ä¹¦åç§°", "certificate"],
            "è¯­è¨€": ["å¤–è¯­æ°´å¹³", "è¯­è¨€èƒ½åŠ›", "language"],
            "é¡¹ç›®ç»éªŒ": ["é¡¹ç›®", "é¡¹ç›®ç»å†", "project"]
        }

        # æ„å»ºåå‘æ˜ å°„
        self.reverse_synonym_mapping = {}
        for standard, synonyms in self.synonym_mapping.items():
            for synonym in synonyms:
                self.reverse_synonym_mapping[synonym.lower()] = standard

    def match_fields(
        self,
        llm_field_mappings: Dict[str, Any],
        form_fields: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        åŒ¹é…å­—æ®µ

        Args:
            llm_field_mappings: å¤§æ¨¡å‹è¯†åˆ«çš„å­—æ®µæ˜ å°„ {"æ¯•ä¸šé™¢æ ¡": "åŒ—äº¬å¤§å­¦"}
            form_fields: è¡¨å•å­—æ®µåˆ—è¡¨ [{"selector": "#school", "label": "å­¦æ ¡"}]

        Returns:
            åŒ¹é…ç»“æœ
        """
        try:
            logger.info(f"ğŸ” å¼€å§‹å­—æ®µåŒ¹é…: LLMè¯†åˆ«{len(llm_field_mappings)}ä¸ªå­—æ®µ, è¡¨å•æœ‰{len(form_fields)}ä¸ªå­—æ®µ")

            # æ„å»ºè¡¨å•å­—æ®µæ ‡ç­¾ç´¢å¼•
            form_field_labels = {field['label']: field for field in form_fields}

            matching_results = []
            unmatched_llm_fields = []
            unmatched_form_fields = list(form_fields)

            # å¯¹æ¯ä¸ªLLMè¯†åˆ«çš„å­—æ®µè¿›è¡ŒåŒ¹é…
            for llm_label, llm_value in llm_field_mappings.items():
                best_match = self._find_best_match(llm_label, form_field_labels)

                if best_match:
                    match_info, form_field = best_match
                    matching_results.append({
                        'selector': form_field['selector'],
                        'type': form_field.get('type', 'text'),
                        'llm_label': llm_label,
                        'form_label': form_field['label'],
                        'value': llm_value,
                        'match_type': match_info['match_type'],
                        'confidence': match_info['confidence'],
                        'required': form_field.get('required', False)
                    })

                    # ä»æœªåŒ¹é…åˆ—è¡¨ä¸­ç§»é™¤
                    if form_field in unmatched_form_fields:
                        unmatched_form_fields.remove(form_field)
                else:
                    unmatched_llm_fields.append({
                        'label': llm_label,
                        'value': llm_value
                    })

            # ç»Ÿè®¡åŒ¹é…ç»“æœ
            total_llm_fields = len(llm_field_mappings)
            matched_count = len(matching_results)
            match_rate = matched_count / total_llm_fields if total_llm_fields > 0 else 0

            logger.info(f"âœ… å­—æ®µåŒ¹é…å®Œæˆ: {matched_count}/{total_llm_fields} ({match_rate:.1%}) åŒ¹é…æˆåŠŸ")

            return {
                'success': True,
                'matching_results': matching_results,
                'unmatched_llm_fields': unmatched_llm_fields,
                'unmatched_form_fields': [
                    {'selector': f['selector'], 'label': f['label']}
                    for f in unmatched_form_fields
                ],
                'statistics': {
                    'total_llm_fields': total_llm_fields,
                    'total_form_fields': len(form_fields),
                    'matched_count': matched_count,
                    'match_rate': match_rate,
                    'unmatched_llm_count': len(unmatched_llm_fields),
                    'unmatched_form_count': len(unmatched_form_fields)
                }
            }

        except Exception as e:
            logger.error(f"âŒ å­—æ®µåŒ¹é…å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'matching_results': []
            }

    def _find_best_match(
        self,
        llm_label: str,
        form_field_labels: Dict[str, Dict[str, Any]]
    ) -> Optional[Tuple[Dict[str, Any], Dict[str, Any]]]:
        """
        ä¸ºLLMæ ‡ç­¾æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„è¡¨å•å­—æ®µ

        Args:
            llm_label: LLMè¯†åˆ«çš„æ ‡ç­¾
            form_field_labels: è¡¨å•å­—æ®µæ ‡ç­¾å­—å…¸

        Returns:
            åŒ¹é…ä¿¡æ¯å’Œå¯¹åº”çš„è¡¨å•å­—æ®µï¼Œæ— åŒ¹é…è¿”å›None
        """
        best_match = None
        best_confidence = 0.0

        for form_label, form_field in form_field_labels.items():
            match_info = self._calculate_match_score(llm_label, form_label)

            if match_info['confidence'] > best_confidence:
                best_confidence = match_info['confidence']
                best_match = (match_info, form_field)

        # åªè¿”å›ç½®ä¿¡åº¦å¤§äºé˜ˆå€¼çš„åŒ¹é…
        if best_confidence >= 0.6:  # è°ƒä½é˜ˆå€¼ï¼Œæé«˜åŒ¹é…ç‡
            return best_match

        return None

    def _calculate_match_score(self, llm_label: str, form_label: str) -> Dict[str, Any]:
        """
        è®¡ç®—ä¸¤ä¸ªæ ‡ç­¾çš„åŒ¹é…åˆ†æ•°

        Args:
            llm_label: LLMæ ‡ç­¾
            form_label: è¡¨å•æ ‡ç­¾

        Returns:
            åŒ¹é…ä¿¡æ¯
        """
        # 1. ç²¾ç¡®åŒ¹é…ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if llm_label == form_label:
            return {
                'match_type': 'exact',
                'confidence': 1.0
            }

        # 2. åŒä¹‰è¯åŒ¹é…
        synonym_score = self._check_synonym_match(llm_label, form_label)
        if synonym_score > 0:
            return {
                'match_type': 'synonym',
                'confidence': synonym_score
            }

        # 3. åŒ…å«åŒ¹é…
        contain_score = self._check_contain_match(llm_label, form_label)
        if contain_score > 0:
            return {
                'match_type': 'contain',
                'confidence': contain_score
            }

        # 4. æ¨¡ç³ŠåŒ¹é…
        fuzzy_score = self._calculate_fuzzy_score(llm_label, form_label)
        if fuzzy_score > 0.6:
            return {
                'match_type': 'fuzzy',
                'confidence': fuzzy_score
            }

        # 5. è¯­ä¹‰åŒ¹é…ï¼ˆåŸºäºå…³é”®è¯ï¼‰
        semantic_score = self._calculate_semantic_score(llm_label, form_label)
        if semantic_score > 0.7:
            return {
                'match_type': 'semantic',
                'confidence': semantic_score
            }

        return {
            'match_type': 'none',
            'confidence': 0.0
        }

    def _check_synonym_match(self, llm_label: str, form_label: str) -> float:
        """æ£€æŸ¥åŒä¹‰è¯åŒ¹é…"""
        # æ ‡å‡†åŒ–æ ‡ç­¾
        standard_llm = self._normalize_label(llm_label)
        standard_form = self._normalize_label(form_label)

        # æŸ¥æ‰¾æ ‡å‡†å½¢å¼
        llm_standard = self.reverse_synonym_mapping.get(standard_llm.lower(), standard_llm)
        form_standard = self.reverse_synonym_mapping.get(standard_form.lower(), standard_form)

        if llm_standard == form_standard:
            return 0.95

        # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€åŒä¹‰è¯ç»„ä¸­
        for standard, synonyms in self.synonym_mapping.items():
            all_forms = [standard] + synonyms
            if standard_llm in all_forms and standard_form in all_forms:
                return 0.9

        return 0.0

    def _check_contain_match(self, llm_label: str, form_label: str) -> float:
        """æ£€æŸ¥åŒ…å«åŒ¹é…"""
        llm_clean = self._clean_text(llm_label)
        form_clean = self._clean_text(form_label)

        # è¾ƒçŸ­çš„åŒ…å«åœ¨è¾ƒé•¿çš„ä¸­
        shorter, longer = (llm_clean, form_clean) if len(llm_clean) < len(form_clean) else (form_clean, llm_clean)

        if len(shorter) >= 2 and shorter in longer:
            # æ ¹æ®é•¿åº¦æ¯”ä¾‹è°ƒæ•´ç½®ä¿¡åº¦
            ratio = len(shorter) / len(longer)
            return 0.8 + ratio * 0.1  # 0.8-0.9ä¹‹é—´

        return 0.0

    def _calculate_fuzzy_score(self, llm_label: str, form_label: str) -> float:
        """è®¡ç®—æ¨¡ç³ŠåŒ¹é…åˆ†æ•°"""
        llm_clean = self._clean_text(llm_label)
        form_clean = self._clean_text(form_label)

        # ä½¿ç”¨SequenceMatcherè®¡ç®—ç›¸ä¼¼åº¦
        similarity = SequenceMatcher(None, llm_clean, form_clean).ratio()

        # å¯¹çŸ­æ–‡æœ¬ç»™äºˆæ›´é«˜æƒé‡
        min_length = min(len(llm_clean), len(form_clean))
        if min_length <= 4:  # çŸ­æ ‡ç­¾
            similarity *= 1.1

        return min(similarity, 1.0)

    def _calculate_semantic_score(self, llm_label: str, form_label: str) -> float:
        """è®¡ç®—è¯­ä¹‰åŒ¹é…åˆ†æ•°"""
        # æå–å…³é”®è¯
        llm_keywords = self._extract_keywords(llm_label)
        form_keywords = self._extract_keywords(form_label)

        if not llm_keywords or not form_keywords:
            return 0.0

        # è®¡ç®—å…³é”®è¯é‡å åº¦
        intersection = set(llm_keywords) & set(form_keywords)
        union = set(llm_keywords) | set(form_keywords)

        if not union:
            return 0.0

        jaccard_score = len(intersection) / len(union)

        # è€ƒè™‘åŒä¹‰è¯
        synonym_bonus = 0.0
        for llm_kw in llm_keywords:
            for form_kw in form_keywords:
                if self._are_synonyms(llm_kw, form_kw):
                    synonym_bonus += 0.3

        return min(jaccard_score + synonym_bonus, 1.0)

    def _normalize_label(self, label: str) -> str:
        """æ ‡å‡†åŒ–æ ‡ç­¾"""
        # ç§»é™¤æ ‡ç‚¹å’Œç©ºæ ¼
        normalized = re.sub(r'[^\w]', '', label)
        return normalized.strip()

    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬"""
        # ç§»é™¤æ ‡ç‚¹ã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦
        cleaned = re.sub(r'[^\w\u4e00-\u9fa5]', '', text)
        return cleaned.lower()

    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ä½¿ç”¨jiebaåˆ†è¯
        words = jieba.lcut(text)

        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        keywords = []
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'å’Œ', 'ä¸', 'æˆ–', 'åŠ'}

        for word in words:
            if len(word) >= 2 and word not in stop_words:
                keywords.append(word)

        return keywords

    def _are_synonyms(self, word1: str, word2: str) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªè¯æ˜¯å¦ä¸ºåŒä¹‰è¯"""
        for synonyms in self.synonym_mapping.values():
            all_forms = synonyms
            if word1 in all_forms and word2 in all_forms:
                return True
        return False


# å…¨å±€å®ä¾‹
label_matching_service = LabelMatchingService()
