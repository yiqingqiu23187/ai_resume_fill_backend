"""
AIæœåŠ¡æ¨¡å— - é›†æˆé˜¿é‡Œåƒé—®å¤§æ¨¡å‹
"""

import json
import logging
from typing import Dict, List, Optional, Any, Tuple
from dashscope import Generation
from app.core.config import settings

logger = logging.getLogger(__name__)


class AIService:
    """AIæœåŠ¡ç±»"""

    @staticmethod
    def _build_field_matching_prompt(
        resume_text: str,
        form_fields: List[Dict[str, Any]]
    ) -> str:
        """æ„å»ºå­—æ®µåŒ¹é…çš„æç¤ºè¯"""

        # æ ¼å¼åŒ–è¡¨å•å­—æ®µä¿¡æ¯
        fields_info = []
        for field in form_fields:
            field_type = field.get('type', 'text')
            field_name = field.get('name', '')
            field_label = field.get('label', '')
            field_placeholder = field.get('placeholder', '')
            field_options = field.get('options', [])

            field_desc = f"å­—æ®µå: {field_name}"
            if field_label:
                field_desc += f", æ ‡ç­¾: {field_label}"
            if field_placeholder:
                field_desc += f", å ä½ç¬¦: {field_placeholder}"
            field_desc += f", ç±»å‹: {field_type}"

            if field_options:
                field_desc += f", é€‰é¡¹: {field_options}"

            fields_info.append(field_desc)

        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç®€å†ä¿¡æ¯æå–å’Œè¡¨å•å¡«å†™åŠ©æ‰‹ã€‚

è¯·æ ¹æ®ä»¥ä¸‹ç®€å†ä¿¡æ¯ï¼Œä¸ºç»™å®šçš„è¡¨å•å­—æ®µæä¾›åˆé€‚çš„å¡«å†™å†…å®¹ã€‚

ã€ç®€å†ä¿¡æ¯ã€‘ï¼š
{resume_text}

ã€è¡¨å•å­—æ®µã€‘ï¼š
{chr(10).join(f'{i+1}. {info}' for i, info in enumerate(fields_info))}

ã€ä»»åŠ¡è¦æ±‚ã€‘ï¼š
1. ä»”ç»†åˆ†æç®€å†ä¿¡æ¯ï¼Œç†è§£å€™é€‰äººçš„èƒŒæ™¯
2. ä¸ºæ¯ä¸ªè¡¨å•å­—æ®µåŒ¹é…æœ€åˆé€‚çš„å†…å®¹
3. å¦‚æœç®€å†ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
4. å¯¹äºé€‰æ‹©ç±»å‹çš„å­—æ®µï¼Œè¯·ä»ç»™å®šé€‰é¡¹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„
5. æ—¥æœŸæ ¼å¼è¯·ç»Ÿä¸€ä¸º YYYY-MM-DD æˆ– YYYY-MM æ ¼å¼
6. ç”µè¯å·ç ä¿æŒåŸæ ¼å¼
7. åœ°å€ä¿¡æ¯è¦å…·ä½“åˆ°åŸå¸‚

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
è¯·ç›´æ¥è¿”å›ä¸€ä¸ªJSONæ•°ç»„ï¼ŒåŒ…å«æ‰€æœ‰åŒ¹é…ç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ï¼š

[
    {{
        "field_name": "å­—æ®µå",
        "field_type": "å­—æ®µç±»å‹",
        "matched_value": "åŒ¹é…çš„å€¼"
    }}
]
"""
        return prompt

    @staticmethod
    async def match_form_fields(
        resume_text: str,
        form_fields: List[Dict[str, Any]]
    ) -> Tuple[bool, List[Dict[str, Any]], str]:
        """
        ä½¿ç”¨AIåŒ¹é…è¡¨å•å­—æ®µ

        Args:
            resume_text: ç®€å†æ–‡æœ¬å†…å®¹
            form_fields: è¡¨å•å­—æ®µåˆ—è¡¨

        Returns:
            Tuple[success, matches, error_message]
        """
        try:
            # æ„å»ºæç¤ºè¯
            prompt = AIService._build_field_matching_prompt(resume_text, form_fields)

            logger.info(f"AIå­—æ®µåŒ¹é…å¼€å§‹ï¼Œç®€å†é•¿åº¦: {len(resume_text)}, å­—æ®µæ•°é‡: {len(form_fields)}")

            # è°ƒç”¨é˜¿é‡Œåƒé—®API
            response = Generation.call(
                model=settings.AI_MODEL,
                prompt=prompt,
                api_key=settings.DASHSCOPE_API_KEY,
                max_tokens=2000,
                temperature=0.1,  # è¾ƒä½çš„æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º
                top_p=0.8
            )

            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code != 200:
                error_msg = f"AI APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
                logger.error(error_msg)
                return False, [], error_msg

            # è§£æå“åº”å†…å®¹
            ai_output = response.output.text.strip()
            logger.debug(f"AIåŸå§‹è¾“å‡º: {ai_output}")

            # å°è¯•è§£æJSON
            try:
                # æå–JSONéƒ¨åˆ†ï¼ˆå»é™¤å¯èƒ½çš„é¢å¤–æ–‡æœ¬ï¼‰
                json_start = ai_output.find('[')
                json_end = ai_output.rfind(']') + 1

                if json_start == -1 or json_end == 0:
                    raise ValueError("AIè¾“å‡ºä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ•°ç»„æ ¼å¼")

                json_content = ai_output[json_start:json_end]
                matches = json.loads(json_content)

                # éªŒè¯åŒ¹é…ç»“æœæ ¼å¼
                validated_matches = []
                for match in matches:
                    if not isinstance(match, dict):
                        continue

                    validated_match = {
                        'field_name': match.get('field_name', ''),
                        'field_type': match.get('field_type', 'text'),
                        'matched_value': match.get('matched_value', '')
                    }
                    validated_matches.append(validated_match)

                logger.info(f"AIå­—æ®µåŒ¹é…æˆåŠŸï¼ŒåŒ¹é…ç»“æœæ•°é‡: {len(validated_matches)}")
                return True, validated_matches, ""

            except (json.JSONDecodeError, ValueError, KeyError) as e:
                error_msg = f"AIè¾“å‡ºè§£æå¤±è´¥: {str(e)}"
                logger.error(f"{error_msg}, åŸå§‹è¾“å‡º: {ai_output}")
                return False, [], error_msg

        except Exception as e:
            error_msg = f"AIå­—æ®µåŒ¹é…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            logger.error(error_msg)
            return False, [], error_msg

    @staticmethod
    async def analyze_html_form_structure(
        html_content: str,
        resume_data: Dict[str, Any],
        website_url: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ğŸ¯ ä½¿ç”¨å¤§æ¨¡å‹åˆ†æHTMLè¡¨å•ç»“æ„å¹¶åŒ¹é…ç®€å†æ•°æ®

        Args:
            html_content: é¡µé¢HTMLå†…å®¹
            resume_data: ç®€å†æ•°æ®
            website_url: ç½‘ç«™URL

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            logger.info(f"ğŸ”¥ AIServiceå¼€å§‹HTMLåˆ†æ - HTMLé•¿åº¦:{len(html_content)}, ç®€å†æ•°æ®ç±»å‹:{type(resume_data)}")

            # ğŸ¯ ç®€åŒ–HTML - åªä¿ç•™è¡¨å•ç›¸å…³å†…å®¹
            logger.debug(f"ğŸ“„ å¼€å§‹HTMLç®€åŒ–å¤„ç†...")
            simplified_html = AIService._simplify_html_for_analysis(html_content)
            logger.info(f"âœ… HTMLç®€åŒ–å®Œæˆ - åŸé•¿åº¦:{len(html_content)}, ç®€åŒ–å:{len(simplified_html)}")

            # æ„å»ºåˆ†ææç¤ºè¯
            logger.debug(f"ğŸ”§ å¼€å§‹æ„å»ºåˆ†ææç¤ºè¯...")
            try:
                prompt = AIService._build_html_analysis_prompt(simplified_html, resume_data, website_url)
                logger.info(f"âœ… æç¤ºè¯æ„å»ºå®Œæˆ - é•¿åº¦:{len(prompt)}")
            except Exception as prompt_error:
                logger.error(f"âŒ æç¤ºè¯æ„å»ºå¤±è´¥ - é”™è¯¯:{str(prompt_error)}")
                raise prompt_error

            # è°ƒç”¨åƒé—®API
            logger.info(f"ğŸ¤– å¼€å§‹è°ƒç”¨åƒé—®API - æ¨¡å‹:{settings.AI_MODEL}")
            logger.debug(f"ğŸ”‘ APIé…ç½® - æœ‰APIå¯†é’¥:{bool(settings.DASHSCOPE_API_KEY)}")

            try:
                logger.info("ğŸŒŠ ä½¿ç”¨æµå¼è°ƒç”¨ï¼Œé¿å…è¶…æ—¶é—®é¢˜...")

                # ä½¿ç”¨æµå¼è°ƒç”¨
                responses = Generation.call(
                    model=settings.AI_MODEL,
                    prompt=prompt,
                    api_key=settings.DASHSCOPE_API_KEY,
                    stream=True  # å¯ç”¨æµå¼è°ƒç”¨
                )

                # æ”¶é›†æµå¼å“åº”
                ai_output = ""
                chunk_count = 0
                logger.debug("ğŸ“¡ å¼€å§‹æ¥æ”¶æµå¼æ•°æ®...")

                for response in responses:
                    if response.status_code == 200:
                        # æµå¼è¾“å‡ºï¼šä½¿ç”¨æœ€æ–°çš„å®Œæ•´å†…å®¹ï¼Œä¸æ˜¯å¢é‡æ‹¼æ¥
                        ai_output = response.output.text  # ç›´æ¥èµ‹å€¼ï¼Œä¸æ˜¯ç´¯åŠ 
                        chunk_count += 1
                        # åªæ˜¾ç¤ºæ¥æ”¶è¿›åº¦ï¼Œä¸è¾“å‡ºå…·ä½“å†…å®¹
                        if chunk_count % 5 == 0:  # æ¯5ä¸ªchunkæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                            logger.debug(f"ğŸ“¦ å·²æ¥æ”¶ {chunk_count} ä¸ªæ•°æ®å—ï¼Œå½“å‰æ€»é•¿åº¦: {len(ai_output)}")
                    else:
                        error_msg = f"æµå¼å“åº”é”™è¯¯ - çŠ¶æ€ç :{response.status_code}, é”™è¯¯ç :{getattr(response, 'code', 'unknown')}"
                        logger.error(f"âŒ {error_msg}")
                        raise Exception(error_msg)

                logger.info(f"âœ… æµå¼æ¥æ”¶å®Œæˆ - å…±æ¥æ”¶ {chunk_count} ä¸ªæ•°æ®å—ï¼Œæ€»è¾“å‡ºé•¿åº¦:{len(ai_output)}")
                # åªåœ¨æœ€åè¾“å‡ºå®Œæ•´å†…å®¹
                logger.info(f"ğŸ“ AIæœ€ç»ˆè¾“å‡º:\n{ai_output}")

                # è§£æAIè¾“å‡º
                logger.debug(f"ğŸ” å¼€å§‹è§£æAIè¾“å‡º...")
                try:
                    result = AIService._parse_html_analysis_output(ai_output)
                    logger.info(f"ğŸ‰ AIè¾“å‡ºè§£æå®Œæˆ - æˆåŠŸ:{result.get('success', False)}")
                    return result
                except Exception as parse_error:
                    logger.error(f"âŒ AIè¾“å‡ºè§£æå¤±è´¥ - é”™è¯¯:{str(parse_error)}")
                    return {"success": False, "error": f"è¾“å‡ºè§£æå¤±è´¥: {str(parse_error)}"}

            except Exception as api_error:
                logger.error(f"âŒ æµå¼APIè°ƒç”¨å¼‚å¸¸ - é”™è¯¯ç±»å‹:{type(api_error).__name__}, é”™è¯¯ä¿¡æ¯:{str(api_error)}")
                raise api_error

        except Exception as e:
            error_msg = f"HTMLåˆ†æè¿‡ç¨‹å¼‚å¸¸ - ç±»å‹:{type(e).__name__}, ä¿¡æ¯:{str(e)}"
            logger.error(f"âŒ {error_msg}", exc_info=True)
            return {"success": False, "error": error_msg}

    @staticmethod
    def _simplify_html_for_analysis(html_content: str) -> str:
        """
        ğŸ¯ æ™ºèƒ½è¡¨å•æå–ï¼šåªä¿ç•™è¡¨å•ç›¸å…³çš„HTMLç‰‡æ®µ
        """
        import time
        start_time = time.time()

        try:
            from bs4 import BeautifulSoup, Comment

            logger.info(f"ğŸ”„ å¼€å§‹æ™ºèƒ½è¡¨å•æå– - HTMLåŸå§‹å¤§å°:{len(html_content)} å­—ç¬¦")

            # ğŸš¨ è¶…å¤§HTMLé¢„æ£€æŸ¥
            if len(html_content) > 500000:  # 500KB
                logger.warning(f"âš ï¸ HTMLè¿‡å¤§({len(html_content)} å­—ç¬¦)ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
                # å¯ä»¥è€ƒè™‘å…ˆåšåŸºç¡€å‹ç¼©
                html_content = AIService._basic_html_cleanup(html_content)
                logger.info(f"ğŸ“‰ é¢„å‹ç¼©åå¤§å°:{len(html_content)} å­—ç¬¦")

            # Step 1: è§£æHTML
            parse_start = time.time()
            logger.debug("ğŸ”§ Step 1: å¼€å§‹è§£æHTML...")
            soup = BeautifulSoup(html_content, 'html.parser')
            parse_time = time.time() - parse_start
            logger.info(f"âœ… Step 1 å®Œæˆ: HTMLè§£æè€—æ—¶ {parse_time:.2f}ç§’")

            # Step 2: æ¸…ç†æ— ç”¨å…ƒç´ 
            cleanup_start = time.time()
            logger.debug("ğŸ”§ Step 2: å¼€å§‹æ¸…ç†æ— ç”¨å…ƒç´ ...")

            # ç»Ÿè®¡è¦åˆ é™¤çš„å…ƒç´ æ•°é‡
            scripts = soup(['script', 'style', 'link', 'meta', 'noscript'])
            logger.debug(f"ğŸ“‹ å‘ç°æ— ç”¨å…ƒç´ : {len(scripts)} ä¸ª")

            for i, element in enumerate(scripts):
                if i % 50 == 0:  # æ¯50ä¸ªå…ƒç´ è¾“å‡ºè¿›åº¦
                    logger.debug(f"ğŸ—‘ï¸ æ¸…ç†è¿›åº¦: {i}/{len(scripts)}")
                element.decompose()

            # ç§»é™¤æ³¨é‡Š
            comments = soup(text=lambda text: isinstance(text, Comment))
            logger.debug(f"ğŸ“‹ å‘ç°æ³¨é‡Š: {len(comments)} ä¸ª")
            for comment in comments:
                comment.extract()

            cleanup_time = time.time() - cleanup_start
            logger.info(f"âœ… Step 2 å®Œæˆ: å…ƒç´ æ¸…ç†è€—æ—¶ {cleanup_time:.2f}ç§’")

            # Step 3: æå–è¡¨å•å…ƒç´ 
            extract_start = time.time()
            logger.debug("ğŸ”§ Step 3: å¼€å§‹æå–è¡¨å•å…ƒç´ ...")
            form_elements = AIService._extract_form_elements_with_context(soup)
            extract_time = time.time() - extract_start
            logger.info(f"âœ… Step 3 å®Œæˆ: è¡¨å•æå–è€—æ—¶ {extract_time:.2f}ç§’, å‘ç° {len(form_elements)} ä¸ªè¡¨å•å…ƒç´ ")

            if not form_elements:
                logger.warning("âš ï¸ æœªå‘ç°è¡¨å•å…ƒç´ ï¼Œé™çº§ä½¿ç”¨åŸºç¡€æ¸…ç†")
                return AIService._basic_html_cleanup(html_content)

            # ğŸš¨ å…ƒç´ æ•°é‡é™åˆ¶
            if len(form_elements) > 200:
                logger.warning(f"âš ï¸ è¡¨å•å…ƒç´ è¿‡å¤š({len(form_elements)}ä¸ª)ï¼Œé™åˆ¶ä¸ºå‰200ä¸ª")
                form_elements = form_elements[:200]

            # Step 4: é‡æ„HTML
            rebuild_start = time.time()
            logger.debug("ğŸ”§ Step 4: å¼€å§‹é‡æ„HTML...")
            simplified_html = AIService._reconstruct_form_html(form_elements)
            rebuild_time = time.time() - rebuild_start
            logger.info(f"âœ… Step 4 å®Œæˆ: HTMLé‡æ„è€—æ—¶ {rebuild_time:.2f}ç§’")

            # æ€»ç»“
            total_time = time.time() - start_time
            compression_ratio = (1 - len(simplified_html) / len(html_content)) * 100
            logger.info(f"ğŸ‰ æ™ºèƒ½è¡¨å•æå–å®Œæˆ!")
            logger.info(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯: åŸé•¿åº¦:{len(html_content)}, ç²¾ç®€å:{len(simplified_html)}, å‹ç¼©ç‡:{compression_ratio:.1f}%")
            logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’ (è§£æ:{parse_time:.2f}s + æ¸…ç†:{cleanup_time:.2f}s + æå–:{extract_time:.2f}s + é‡æ„:{rebuild_time:.2f}s)")

            return simplified_html

        except ImportError as e:
            logger.warning(f"âš ï¸ BeautifulSoupæœªå®‰è£…: {str(e)}ï¼Œé™çº§ä½¿ç”¨åŸºç¡€æ¸…ç†")
            return AIService._basic_html_cleanup(html_content)
        except Exception as e:
            total_time = time.time() - start_time
            logger.error(f"âŒ æ™ºèƒ½è¡¨å•æå–å¼‚å¸¸ (è€—æ—¶:{total_time:.2f}ç§’): {type(e).__name__}: {str(e)}", exc_info=True)
            logger.warning("ğŸ”„ é™çº§ä½¿ç”¨åŸºç¡€æ¸…ç†")
            return AIService._basic_html_cleanup(html_content)

    @staticmethod
    def _extract_form_elements_with_context(soup):
        """
        ğŸ” æå–è¡¨å•å…ƒç´ åŠå…¶å¿…è¦ä¸Šä¸‹æ–‡
        """
        import time
        extract_start = time.time()
        form_data = []

        # Step 3.1: æŸ¥æ‰¾æ‰€æœ‰è¡¨å•ç›¸å…³å…ƒç´ 
        find_start = time.time()
        logger.debug("ğŸ” Step 3.1: æŸ¥æ‰¾è¡¨å•å…ƒç´ ...")
        form_elements = soup.find_all(['input', 'textarea', 'select', 'button'])
        find_time = time.time() - find_start

        logger.info(f"ğŸ“‹ Step 3.1 å®Œæˆ: å‘ç° {len(form_elements)} ä¸ªè¡¨å•å…ƒç´  (è€—æ—¶:{find_time:.2f}ç§’)")

        # ğŸš¨ å…ƒç´ æ•°é‡é¢„è­¦
        if len(form_elements) > 500:
            logger.warning(f"âš ï¸ è¡¨å•å…ƒç´ æ•°é‡è¾ƒå¤š({len(form_elements)}ä¸ª)ï¼Œå¤„ç†å¯èƒ½è¾ƒæ…¢")

        valid_count = 0
        for i, element in enumerate(form_elements):
            # è¿›åº¦æ—¥å¿—
            if i % 20 == 0 and i > 0:
                elapsed = time.time() - extract_start
                logger.debug(f"ğŸ”„ å¤„ç†è¿›åº¦: {i}/{len(form_elements)} ({(i/len(form_elements)*100):.1f}%) - å·²è€—æ—¶:{elapsed:.2f}ç§’")

            # è·³è¿‡ä¸ç›¸å…³çš„æŒ‰é’®å’Œéšè—å…ƒç´ 
            if (element.name == 'input' and
                element.get('type') in ['button', 'submit', 'reset', 'hidden']):
                continue

            element_start = time.time()
            valid_count += 1

            element_data = {
                'element': element,
                'labels': [],
                'containers': [],
                'context_text': []
            }

            # Step 3.2: æŸ¥æ‰¾å…³è”çš„æ ‡ç­¾
            try:
                labels_start = time.time()
                element_data['labels'] = AIService._find_associated_labels(element, soup)
                labels_time = time.time() - labels_start

                if labels_time > 0.5:  # å¦‚æœå•ä¸ªæ ‡ç­¾æŸ¥æ‰¾è¶…è¿‡0.5ç§’
                    logger.debug(f"âš ï¸ æ ‡ç­¾æŸ¥æ‰¾è¾ƒæ…¢: å…ƒç´ {valid_count} è€—æ—¶{labels_time:.2f}ç§’")

            except Exception as e:
                logger.warning(f"âš ï¸ æ ‡ç­¾æŸ¥æ‰¾å¼‚å¸¸ - å…ƒç´ {valid_count}: {str(e)}")
                element_data['labels'] = []

            # Step 3.3: æŸ¥æ‰¾çˆ¶çº§å®¹å™¨
            try:
                containers_start = time.time()
                element_data['containers'] = AIService._find_form_containers(element)
                containers_time = time.time() - containers_start

                if containers_time > 0.5:
                    logger.debug(f"âš ï¸ å®¹å™¨æŸ¥æ‰¾è¾ƒæ…¢: å…ƒç´ {valid_count} è€—æ—¶{containers_time:.2f}ç§’")

            except Exception as e:
                logger.warning(f"âš ï¸ å®¹å™¨æŸ¥æ‰¾å¼‚å¸¸ - å…ƒç´ {valid_count}: {str(e)}")
                element_data['containers'] = []

            # Step 3.4: æŸ¥æ‰¾ä¸Šä¸‹æ–‡æ–‡å­—
            try:
                context_start = time.time()
                element_data['context_text'] = AIService._find_context_text(element)
                context_time = time.time() - context_start

                if context_time > 0.5:
                    logger.debug(f"âš ï¸ ä¸Šä¸‹æ–‡æŸ¥æ‰¾è¾ƒæ…¢: å…ƒç´ {valid_count} è€—æ—¶{context_time:.2f}ç§’")

            except Exception as e:
                logger.warning(f"âš ï¸ ä¸Šä¸‹æ–‡æŸ¥æ‰¾å¼‚å¸¸ - å…ƒç´ {valid_count}: {str(e)}")
                element_data['context_text'] = []

            element_time = time.time() - element_start
            if element_time > 1.0:  # å•ä¸ªå…ƒç´ å¤„ç†è¶…è¿‡1ç§’
                logger.debug(f"ğŸŒ å…ƒç´ {valid_count}å¤„ç†è¾ƒæ…¢: {element_time:.2f}ç§’ - {element.name}.{element.get('type', 'unknown')}")

            form_data.append(element_data)

            # ğŸš¨ è¶…æ—¶ä¿æŠ¤ï¼šå¦‚æœå¤„ç†æ—¶é—´è¿‡é•¿ï¼Œæå‰é€€å‡º
            total_elapsed = time.time() - extract_start
            if total_elapsed > 30.0:  # 30ç§’è¶…æ—¶
                logger.warning(f"â° è¡¨å•æå–è¶…æ—¶({total_elapsed:.2f}ç§’)ï¼Œå·²å¤„ç†{len(form_data)}/{len(form_elements)}ä¸ªå…ƒç´ ")
                break

        total_time = time.time() - extract_start
        logger.info(f"âœ… è¡¨å•å…ƒç´ å¤„ç†å®Œæˆ: {len(form_data)}/{len(form_elements)} ä¸ªæœ‰æ•ˆå…ƒç´  (æ€»è€—æ—¶:{total_time:.2f}ç§’)")

        return form_data

    @staticmethod
    def _find_associated_labels(element, soup):
        """æŸ¥æ‰¾ä¸è¡¨å•å…ƒç´ å…³è”çš„æ ‡ç­¾"""
        labels = []

        try:
            # æ–¹æ³•1: é€šè¿‡forå±æ€§æŸ¥æ‰¾ (æœ€å¿«é€Ÿçš„æ–¹æ³•)
            element_id = element.get('id')
            if element_id:
                label = soup.find('label', {'for': element_id})
                if label:
                    labels.append(label)

            # æ–¹æ³•2: æŸ¥æ‰¾åŒ…è£¹çš„label (æ·»åŠ æ·±åº¦é™åˆ¶)
            parent = element.parent
            depth = 0
            max_depth = 10  # æœ€å¤šå‘ä¸ŠæŸ¥æ‰¾10å±‚

            while parent and parent.name != 'html' and depth < max_depth:
                if parent.name == 'label':
                    labels.append(parent)
                    break
                parent = parent.parent
                depth += 1

            # å¦‚æœè¾¾åˆ°æœ€å¤§æ·±åº¦ï¼Œè®°å½•è­¦å‘Š
            if depth >= max_depth:
                logger.debug(f"âš ï¸ æ ‡ç­¾æŸ¥æ‰¾è¾¾åˆ°æœ€å¤§æ·±åº¦({max_depth})ï¼Œå¯èƒ½å­˜åœ¨å¤æ‚åµŒå¥—")

            # æ–¹æ³•3: æŸ¥æ‰¾ç›¸é‚»çš„label (åªåœ¨æ²¡æ‰¾åˆ°æ—¶æ‰§è¡Œ)
            if not labels:
                # å‘å‰æŸ¥æ‰¾ (é™åˆ¶èŒƒå›´)
                prev_sibling = element.find_previous_sibling('label')
                if prev_sibling:
                    labels.append(prev_sibling)

                # å‘åæŸ¥æ‰¾ (é™åˆ¶èŒƒå›´)
                next_sibling = element.find_next_sibling('label')
                if next_sibling:
                    labels.append(next_sibling)

        except Exception as e:
            logger.debug(f"æ ‡ç­¾æŸ¥æ‰¾å¼‚å¸¸: {str(e)}")

        return labels

    @staticmethod
    def _find_form_containers(element):
        """æŸ¥æ‰¾è¡¨å•å…ƒç´ çš„å®¹å™¨å±‚æ¬¡"""
        containers = []

        try:
            # å‘ä¸ŠæŸ¥æ‰¾é‡è¦çš„å®¹å™¨å…ƒç´  (æ·»åŠ æ·±åº¦é™åˆ¶)
            parent = element.parent
            important_tags = {'form', 'fieldset', 'div', 'section', 'article', 'td', 'th', 'li'}
            depth = 0
            max_depth = 15  # æœ€å¤šå‘ä¸ŠæŸ¥æ‰¾15å±‚
            max_containers = 3  # æœ€å¤šä¿ç•™3ä¸ªå®¹å™¨

            while (parent and parent.name != 'html' and
                   len(containers) < max_containers and depth < max_depth):

                if parent.name in important_tags:
                    # åªä¿ç•™æœ‰æ„ä¹‰çš„å®¹å™¨
                    if (parent.get('class') or parent.get('id') or
                        parent.name in {'form', 'fieldset', 'td', 'th'}):
                        containers.insert(0, parent)

                parent = parent.parent
                depth += 1

            # å¦‚æœè¾¾åˆ°æœ€å¤§æ·±åº¦ï¼Œè®°å½•è°ƒè¯•ä¿¡æ¯
            if depth >= max_depth:
                logger.debug(f"âš ï¸ å®¹å™¨æŸ¥æ‰¾è¾¾åˆ°æœ€å¤§æ·±åº¦({max_depth})ï¼Œå¯èƒ½å­˜åœ¨æ·±åº¦åµŒå¥—")

        except Exception as e:
            logger.debug(f"å®¹å™¨æŸ¥æ‰¾å¼‚å¸¸: {str(e)}")

        return containers

    @staticmethod
    def _find_context_text(element):
        """æŸ¥æ‰¾å…ƒç´ å‘¨å›´çš„ä¸Šä¸‹æ–‡æ–‡å­—"""
        context_texts = []

        try:
            # æŸ¥æ‰¾ç›¸é‚»çš„æ–‡æœ¬èŠ‚ç‚¹ (æ·»åŠ æ•°é‡é™åˆ¶)
            sibling_count = 0
            max_siblings = 5  # æœ€å¤šæ£€æŸ¥5ä¸ªå…„å¼Ÿå…ƒç´ 

            # å‘å‰æŸ¥æ‰¾
            for sibling in element.previous_siblings:
                if sibling_count >= max_siblings:
                    break

                if hasattr(sibling, 'get_text'):
                    text = sibling.get_text(strip=True)
                    if text and len(text) < 100:  # é¿å…è¿‡é•¿çš„æ–‡æœ¬
                        context_texts.insert(0, text)
                        break
                sibling_count += 1

            # å‘åæŸ¥æ‰¾
            sibling_count = 0
            for sibling in element.next_siblings:
                if sibling_count >= max_siblings:
                    break

                if hasattr(sibling, 'get_text'):
                    text = sibling.get_text(strip=True)
                    if text and len(text) < 100:
                        context_texts.append(text)
                        break
                sibling_count += 1

        except Exception as e:
            logger.debug(f"ä¸Šä¸‹æ–‡æ–‡å­—æŸ¥æ‰¾å¼‚å¸¸: {str(e)}")

        return context_texts

    @staticmethod
    def _reconstruct_form_html(form_data):
        """
        ğŸ—ï¸ é‡æ–°æ„é€ ç²¾ç®€çš„HTMLç»“æ„
        """
        html_parts = ['<!DOCTYPE html><html><head><meta charset="utf-8"></head><body>']

        for data in form_data:
            element = data['element']

            # æ„å»ºå®¹å™¨ç»“æ„
            container_html = AIService._build_container_html(data['containers'])
            html_parts.append(container_html['open'])

            # æ·»åŠ æ ‡ç­¾
            for label in data['labels']:
                # ç®€åŒ–æ ‡ç­¾ï¼Œåªä¿ç•™æ–‡æœ¬å†…å®¹
                label_text = label.get_text(strip=True)
                if label_text:
                    html_parts.append(f'<label>{label_text}</label>')

            # æ·»åŠ ä¸Šä¸‹æ–‡æ–‡å­—
            for text in data['context_text']:
                html_parts.append(f'<span>{text}</span>')

            # ğŸ¯ æ ¸å¿ƒä¼˜åŒ–ï¼šç®€åŒ–è¡¨å•å…ƒç´ 
            simplified_element = AIService._simplify_form_element(element)
            html_parts.append(simplified_element)

            html_parts.append(container_html['close'])

        html_parts.append('</body></html>')

        return '\n'.join(html_parts)

    @staticmethod
    def _simplify_form_element(element):
        """
        ğŸ¯ æåº¦ç®€åŒ–è¡¨å•å…ƒç´ ï¼Œç§»é™¤å†—ä½™ä¿¡æ¯
        """
        tag_name = element.name

        # ä¿ç•™çš„é‡è¦å±æ€§
        important_attrs = ['id', 'name', 'type', 'placeholder', 'value', 'required']

        # æ„å»ºç®€åŒ–çš„å±æ€§
        attrs = []
        for attr in important_attrs:
            value = element.get(attr)
            if value and str(value).strip():
                # æˆªæ–­è¿‡é•¿çš„å€¼
                if len(str(value)) > 50:
                    value = str(value)[:47] + "..."
                attrs.append(f'{attr}="{value}"')

        # å¤„ç†selectå…ƒç´ çš„é€‰é¡¹
        if tag_name == 'select':
            attr_str = ' ' + ' '.join(attrs) if attrs else ''
            options_html = AIService._simplify_select_options(element)
            return f'<{tag_name}{attr_str}>{options_html}</{tag_name}>'
        else:
            attr_str = ' ' + ' '.join(attrs) if attrs else ''
            return f'<{tag_name}{attr_str}/>'

    @staticmethod
    def _simplify_select_options(select_element):
        """
        ğŸ¯ æåº¦ç®€åŒ–selecté€‰é¡¹ - åªä¿ç•™å‰3ä¸ªå’Œ"å…¶ä»–"ç±»é€‰é¡¹
        """
        options = select_element.find_all('option')

        if len(options) <= 5:
            # é€‰é¡¹è¾ƒå°‘ï¼Œå…¨éƒ¨ä¿ç•™ä½†ç®€åŒ–
            simplified_options = []
            for opt in options:
                value = opt.get('value', '')
                text = opt.get_text(strip=True)
                if text:
                    # æˆªæ–­è¿‡é•¿çš„å€¼å’Œæ–‡æœ¬
                    if len(value) > 30:
                        value = value[:27] + "..."
                    if len(text) > 20:
                        text = text[:17] + "..."
                    simplified_options.append(f'<option value="{value}">{text}</option>')
            return ''.join(simplified_options)
        else:
            # é€‰é¡¹å¾ˆå¤šï¼Œåªä¿ç•™ä»£è¡¨æ€§çš„
            simplified_options = []

            # ä¿ç•™å‰3ä¸ªé€‰é¡¹
            for i, opt in enumerate(options[:3]):
                value = opt.get('value', '')[:20]  # é™åˆ¶é•¿åº¦
                text = opt.get_text(strip=True)[:15]  # é™åˆ¶é•¿åº¦
                if text:
                    simplified_options.append(f'<option value="{value}">{text}</option>')

            # å¦‚æœæœ‰å¾ˆå¤šé€‰é¡¹ï¼Œæ·»åŠ çœç•¥æç¤º
            if len(options) > 3:
                simplified_options.append(f'<!-- ...è¿˜æœ‰{len(options)-3}ä¸ªé€‰é¡¹ -->')

                # æŸ¥æ‰¾å¹¶ä¿ç•™"å…¶ä»–"ã€"è¯·é€‰æ‹©"ç­‰é‡è¦é€‰é¡¹
                for opt in options[3:]:
                    text = opt.get_text(strip=True).lower()
                    if any(keyword in text for keyword in ['å…¶ä»–', 'å…¶å®ƒ', 'è¯·é€‰æ‹©', 'other', 'select']):
                        value = opt.get('value', '')[:20]
                        text = opt.get_text(strip=True)[:15]
                        simplified_options.append(f'<option value="{value}">{text}</option>')
                        break  # åªä¿ç•™ç¬¬ä¸€ä¸ªåŒ¹é…çš„

            return ''.join(simplified_options)

    @staticmethod
    def _build_container_html(containers):
        """æ„å»ºå®¹å™¨çš„å¼€å¯å’Œå…³é—­æ ‡ç­¾"""
        open_tags = []
        close_tags = []

        for container in containers:
            # ç®€åŒ–å®¹å™¨å±æ€§ï¼Œåªä¿ç•™é‡è¦çš„classå’Œid
            attrs = []
            if container.get('class'):
                class_str = ' '.join(container.get('class'))
                attrs.append(f'class="{class_str}"')
            if container.get('id'):
                attrs.append(f'id="{container.get("id")}"')

            attr_str = ' ' + ' '.join(attrs) if attrs else ''
            open_tags.append(f'<{container.name}{attr_str}>')
            close_tags.insert(0, f'</{container.name}>')

        return {
            'open': '\n'.join(open_tags),
            'close': '\n'.join(close_tags)
        }

    @staticmethod
    def _basic_html_cleanup(html_content: str) -> str:
        """åŸºç¡€HTMLæ¸…ç†ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        import re

        # ç§»é™¤scriptå’Œstyleæ ‡ç­¾
        html_content = re.sub(r'<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>', '', html_content, flags=re.IGNORECASE)
        html_content = re.sub(r'<style\b[^<]*(?:(?!<\/style>)<[^<]*)*<\/style>', '', html_content, flags=re.IGNORECASE)

        # ç§»é™¤æ³¨é‡Š
        html_content = re.sub(r'<!--.*?-->', '', html_content, flags=re.DOTALL)

        # å‹ç¼©ç©ºç™½
        html_content = re.sub(r'\s+', ' ', html_content)

        # é™åˆ¶é•¿åº¦
        if len(html_content) > 50000:
            html_content = html_content[:50000] + "..."
            logger.warning("HTMLå†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­å¤„ç†")

        return html_content.strip()

    @staticmethod
    def _build_html_analysis_prompt(
        html_content: str,
        resume_data: Dict[str, Any],
        website_url: Optional[str] = None
    ) -> str:
        """
        æ„å»ºHTMLåˆ†æçš„æç¤ºè¯
        """
        resume_text = json.dumps(resume_data, ensure_ascii=False, indent=2)

        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¡¨å•è‡ªåŠ¨å¡«å†™åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æHTMLè¡¨å•ï¼Œè¯†åˆ«æ‰€æœ‰å¯å¡«å†™çš„å­—æ®µï¼Œå¹¶æ ¹æ®ç®€å†ä¿¡æ¯ä¸ºæ¯ä¸ªå­—æ®µæä¾›åˆé€‚çš„å¡«å†™å€¼ï¼Œç¡®ä¿è¡¨å•å¡«å†™çš„å®Œæ•´æ€§ã€‚

HTMLè¡¨å•å†…å®¹ï¼š
```html
{html_content}
```

ç®€å†ä¿¡æ¯ï¼š
```json
{resume_text}
```

ä»»åŠ¡è¦æ±‚ï¼š
1. è¯†åˆ«æ‰€æœ‰éœ€è¦ç”¨æˆ·å¡«å†™çš„è¡¨å•å­—æ®µï¼ˆinputã€selectã€textareaç­‰ï¼‰
2. è·³è¿‡ä»¥ä¸‹ç±»å‹çš„å­—æ®µï¼š
   - éšè—å­—æ®µ(type="hidden")
   - æŒ‰é’®(type="button/submit/reset")
   - åªè¯»å­—æ®µ(readonly="true")
   - æ–‡ä»¶ä¸Šä¼ (type="file")
3. å°½åŠ›ä¸ºæ¯ä¸ªå¯å¡«å†™å­—æ®µåŒ¹é…ç®€å†ä¸­çš„å¯¹åº”ä¿¡æ¯
4. é‡è¦ï¼šåªè¾“å‡ºèƒ½å¤Ÿä»ç®€å†ä¸­åŒ¹é…åˆ°å…·ä½“å€¼çš„å­—æ®µï¼Œå¦‚æœç®€å†ä¸­åŒ¹é…ä¸åˆ°ç›¸å…³ä¿¡æ¯ï¼Œè·³è¿‡è¯¥å­—æ®µ

è¾“å‡ºJSONæ ¼å¼ï¼ˆç›´æ¥è¾“å‡ºæ•°ç»„ï¼Œä¸è¦å…¶ä»–è¯´æ˜æ–‡å­—ï¼‰ï¼š
[
  {{
    "name": "å­—æ®µçš„nameå±æ€§",
    "type": "å­—æ®µç±»å‹(input/select/textarea)",
    "selector": "CSSé€‰æ‹©å™¨(ä½¿ç”¨å±æ€§é€‰æ‹©å™¨æ ¼å¼ï¼š[id='å­—æ®µid'] æˆ– [name='å­—æ®µname'])",
    "value": "åŒ¹é…çš„å¡«å†™å€¼"
  }}
]

"""
        return prompt

    @staticmethod
    def _parse_html_analysis_output(ai_output: str) -> Dict[str, Any]:
        """
        è§£æAI HTMLåˆ†æè¾“å‡º - ç®€åŒ–ç‰ˆæœ¬
        """
        try:
            # æå–JSONéƒ¨åˆ†
            import re
            json_start = ai_output.find('[')
            json_end = ai_output.rfind(']') + 1

            if json_start == -1 or json_end == 0:
                raise ValueError("AIè¾“å‡ºä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ•°ç»„")

            json_str = ai_output[json_start:json_end]
            fields_array = json.loads(json_str)

            # éªŒè¯å’Œè½¬æ¢å­—æ®µæ ¼å¼
            validated_fields = []
            for field in fields_array:
                if isinstance(field, dict) and field.get("name"):
                    validated_field = {
                        'name': field.get('name', ''),
                        'type': field.get('type', 'input'),  # ä½¿ç”¨AIè¯†åˆ«çš„ç±»å‹
                        'label': field.get('name', ''),  # ä½¿ç”¨nameä½œä¸ºlabel
                        'selector': field.get('selector', f"[name='{field.get('name', '')}']"),  # ä½¿ç”¨AIæä¾›çš„é€‰æ‹©å™¨
                        'required': False,
                        'category': 'å…¶ä»–',  # ç®€åŒ–åˆ†ç±»
                        'matched_value': field.get('value', '')
                    }
                    validated_fields.append(validated_field)

            logger.info(f"HTMLåˆ†ææˆåŠŸï¼Œè¯†åˆ«å­—æ®µæ•°é‡: {len(validated_fields)}")

            return {
                "success": True,
                "analyzed_fields": validated_fields,
                "form_structure": {}  # ç©ºçš„ç»“æ„ä¿¡æ¯
            }

        except (json.JSONDecodeError, ValueError, KeyError) as e:
            error_msg = f"AI HTMLåˆ†æè¾“å‡ºè§£æå¤±è´¥: {str(e)}"
            logger.error(f"{error_msg}, åŸå§‹è¾“å‡ºå‰500å­—ç¬¦: {ai_output[:500]}...")
            return {"success": False, "error": error_msg}
