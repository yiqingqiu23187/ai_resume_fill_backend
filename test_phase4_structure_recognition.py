#!/usr/bin/env python3
"""
Phase 4: ç»“æ„è¯†åˆ«æµ‹è¯•è„šæœ¬

æµ‹è¯•ä»Phase 2çš„å¹³é“ºå­—æ®µåˆ°Phase 4çš„ç»“æ„åŒ–åˆ†ç»„è½¬æ¢
å±•ç¤ºæ™ºèƒ½è¯­ä¹‰åŒ¹é…å’Œæ¨¡ç³ŠåŒ¹é…çš„æ•ˆæœ
"""

import asyncio
import sys
import json
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from app.services.visual.visual_analysis_service import visual_analysis_service
from app.services.structure.structure_recognition_service import structure_recognition_service
from test_phase2_cv_algorithms import create_complex_test_html


async def test_phase4_complete_pipeline():
    """æµ‹è¯•Phase 2 + Phase 4çš„å®Œæ•´ç®¡é“"""
    print("ğŸš€ Phase 4ç»“æ„è¯†åˆ«æµ‹è¯• - å®Œæ•´ç®¡é“")
    print("=" * 80)

    try:
        # ç¬¬ä¸€æ­¥: è¿è¡ŒPhase 2è·å–åŸºç¡€æ•°æ®
        print("ğŸ“Š ç¬¬ä¸€æ­¥: è¿è¡ŒPhase 2ç®€åŒ–ç‰ˆ...")
        test_html = create_complex_test_html()

        phase2_result = await visual_analysis_service.analyze_html_visual(
            html_content=test_html,
            website_url="test://phase4/structure-recognition",
            analysis_config={'viewport_width': 1200, 'viewport_height': 1400}
        )

        if not phase2_result.get('success'):
            print(f"âŒ Phase 2å¤±è´¥: {phase2_result.get('error')}")
            return

        print(f"âœ… Phase 2å®Œæˆ: {phase2_result['elements']['total_count']}ä¸ªå­—æ®µ")
        print(f"ğŸ“‹ æ ‡ç­¾è¦†ç›–ç‡: {phase2_result['summary']['quality_metrics']['labeling_rate']}%")

        # ç¬¬äºŒæ­¥: è¿è¡ŒPhase 4ç»“æ„è¯†åˆ«
        print("\nğŸ¯ ç¬¬äºŒæ­¥: è¿è¡ŒPhase 4ç»“æ„è¯†åˆ«...")
        start_time = time.time()

        phase4_result = await structure_recognition_service.recognize_structure(phase2_result)

        analysis_time = time.time() - start_time

        if phase4_result.get('success'):
            print_phase4_results(phase4_result, analysis_time)
        else:
            print(f"âŒ Phase 4å¤±è´¥: {phase4_result.get('error')}")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

    finally:
        # æ¸…ç†èµ„æº
        try:
            await visual_analysis_service.cleanup_resources()
        except:
            pass


def print_phase4_results(result: dict, analysis_time: float):
    """æ‰“å°Phase 4ç»“æœçš„è¯¦ç»†ä¿¡æ¯"""

    print(f"\nâœ… **Phase 4ç»“æ„è¯†åˆ«æˆåŠŸ!**")
    print(f"   â±ï¸ åˆ†æç”¨æ—¶: {analysis_time:.2f}ç§’")
    print(f"   ğŸ“‹ é˜¶æ®µ: {result['phase']}")

    # è½¬æ¢ç»Ÿè®¡
    conversion_stats = result.get('conversion_stats', {})
    print(f"\nğŸ“Š **ç»“æ„è½¬æ¢ç»Ÿè®¡**:")
    print(f"   ğŸ“¥ è¾“å…¥å¹³é“ºå­—æ®µ: {conversion_stats.get('input_flat_fields', 0)}ä¸ª")
    print(f"   ğŸ“¤ è¾“å‡ºé€»è¾‘åˆ†ç»„: {conversion_stats.get('output_logical_groups', 0)}ä¸ª")
    print(f"   ğŸ“ˆ ç»“æ„ç®€åŒ–æ¯”ä¾‹: {conversion_stats.get('structure_reduction_ratio', 0):.1%}")
    print(f"   ğŸ¯ è¯­ä¹‰è¦†ç›–ç‡: {conversion_stats.get('semantic_coverage', 0):.1%}")

    # Phase 4è´¨é‡è¯„ä¼°
    quality = result.get('phase4_quality', {})
    print(f"\nğŸ† **Phase 4è´¨é‡è¯„ä¼°**:")
    print(f"   ğŸŒŸ ç»¼åˆè¯„åˆ†: {quality.get('overall_score', 0):.2f} ({quality.get('level', 'unknown')})")
    print(f"   ğŸ¯ è¯­ä¹‰è¦†ç›–: {quality.get('semantic_coverage', 0):.1%}")
    print(f"   âš–ï¸ åˆ†ç»„å¹³è¡¡: {quality.get('group_balance', 0):.2f}")
    print(f"   ğŸ—ï¸ ç»“æ„å¤æ‚åº¦: {quality.get('structure_complexity', 0):.2f}")

    # é€»è¾‘åˆ†ç»„è¯¦æƒ…
    logical_groups = result.get('logical_groups', [])
    print(f"\nğŸ“‹ **é€»è¾‘åˆ†ç»„è¯¦æƒ…** ({len(logical_groups)}ä¸ªåˆ†ç»„):")

    for i, group in enumerate(logical_groups, 1):
        print(f"\n   ğŸ“‚ **åˆ†ç»„ {i}: {group.get('title', 'Unknown')}**")
        print(f"      ğŸ†” ID: {group.get('id', 'unknown')}")
        print(f"      ğŸ“Š å­—æ®µæ•°é‡: {group.get('field_count', 0)}ä¸ª")
        print(f"      ğŸ”„ å¯é‡å¤: {'æ˜¯' if group.get('is_repeatable', False) else 'å¦'}")
        print(f"      ğŸ¯ ä¼˜å…ˆçº§: {group.get('priority', 999)}")

        # æ˜¾ç¤ºè¯¥åˆ†ç»„çš„å­—æ®µ
        fields = group.get('fields', [])
        if fields:
            print(f"      ğŸ“ åŒ…å«å­—æ®µ:")
            for j, field in enumerate(fields[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ªå­—æ®µ
                label = field.get('label', 'unknown')
                semantic_type = field.get('semantic_type', 'unknown')
                match_score = field.get('match_score', 0)
                print(f"         {j}. {label} ({semantic_type}, å¾—åˆ†: {match_score:.2f})")

            if len(fields) > 5:
                print(f"         ... è¿˜æœ‰{len(fields) - 5}ä¸ªå­—æ®µ")

    # åˆ†ææ‘˜è¦
    summary = result.get('analysis_summary', {})
    if summary:
        print(f"\nğŸ“ˆ **åˆ†ææ‘˜è¦**:")

        # ç»“æ„è´¨é‡
        structure_quality = summary.get('structure_quality', {})
        if structure_quality:
            print(f"   ğŸ“Š æ€»å­—æ®µæ•°: {structure_quality.get('total_fields', 0)}")
            print(f"   ğŸ¯ è¯­ä¹‰åŒ¹é…ç‡: {structure_quality.get('semantic_match_rate', 0):.1%}")
            print(f"   â­ é«˜ç½®ä¿¡åº¦åŒ¹é…: {structure_quality.get('high_confidence_rate', 0):.1%}")

        # å­—æ®µè¦†ç›–
        coverage = summary.get('field_coverage', {})
        if coverage:
            print(f"   ğŸ·ï¸ è¯­ä¹‰ç±»å‹æ•°: {coverage.get('unique_semantic_types', 0)}ç§")
            print(f"   ğŸ“‚ åˆ†ç»„ç±»å‹æ•°: {coverage.get('unique_group_types', 0)}ç§")

        # ä¼˜åŒ–å»ºè®®
        recommendations = summary.get('recommendations', [])
        if recommendations:
            print(f"\nğŸ’¡ **ä¼˜åŒ–å»ºè®®**:")
            for rec in recommendations[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªå»ºè®®
                print(f"   â€¢ {rec}")


async def test_semantic_matching_showcase():
    """å±•ç¤ºè¯­ä¹‰åŒ¹é…çš„æ™ºèƒ½ç¨‹åº¦"""
    print("\n" + "=" * 80)
    print("ğŸ¯ æ™ºèƒ½è¯­ä¹‰åŒ¹é…å±•ç¤º")
    print("=" * 80)

    # æµ‹è¯•å„ç§å˜ä½“çš„å­—æ®µå
    test_cases = [
        {"label": "å§“å", "expected_group": "basic_info", "expected_type": "name"},
        {"label": "çœŸå®å§“å", "expected_group": "basic_info", "expected_type": "name"},
        {"label": "æ¯•ä¸šé™¢æ ¡", "expected_group": "education", "expected_type": "school"},
        {"label": "æ¯•ä¸šå­¦æ ¡", "expected_group": "education", "expected_type": "school"},
        {"label": "å°±è¯»å­¦æ ¡", "expected_group": "education", "expected_type": "school"},
        {"label": "University", "expected_group": "education", "expected_type": "school"},
        {"label": "æ‰‹æœºå·", "expected_group": "basic_info", "expected_type": "phone"},
        {"label": "è”ç³»ç”µè¯", "expected_group": "basic_info", "expected_type": "phone"},
        {"label": "Mobile", "expected_group": "basic_info", "expected_type": "phone"},
        {"label": "å·¥ä½œå•ä½", "expected_group": "work_experience", "expected_type": "company"},
        {"label": "å…¬å¸åç§°", "expected_group": "work_experience", "expected_type": "company"},
        {"label": "Employer", "expected_group": "work_experience", "expected_type": "company"},
    ]

    # åˆ›å»ºæ¨¡ç³ŠåŒ¹é…å™¨è¿›è¡Œæµ‹è¯•
    from app.services.structure.fuzzy_matcher import FuzzyMatcher

    config_path = Path(__file__).parent / "app" / "config" / "semantic_groups.json"
    matcher = FuzzyMatcher(str(config_path))

    print("ğŸ” **æ¨¡ç³ŠåŒ¹é…æµ‹è¯•ç»“æœ**:")
    success_count = 0

    for i, test_case in enumerate(test_cases, 1):
        label = test_case["label"]
        expected_group = test_case["expected_group"]
        expected_type = test_case["expected_type"]

        result = matcher.find_best_match(field_label=label)

        if result:
            actual_group = result.get('group_id')
            actual_type = result.get('field_type')
            score = result.get('score', 0)

            # æ£€æŸ¥åŒ¹é…æ˜¯å¦æ­£ç¡®
            group_match = actual_group == expected_group
            type_match = actual_type == expected_type

            if group_match and type_match:
                status = "âœ… å®Œå…¨åŒ¹é…"
                success_count += 1
            elif group_match:
                status = "ğŸŸ¡ åˆ†ç»„åŒ¹é…"
            else:
                status = "âŒ åŒ¹é…å¤±è´¥"

            print(f"   {i:2d}. {label:12s} â†’ {actual_group}:{actual_type} (å¾—åˆ†: {score:.2f}) {status}")
        else:
            print(f"   {i:2d}. {label:12s} â†’ æ— åŒ¹é… âŒ")

    accuracy = success_count / len(test_cases)
    print(f"\nğŸ“Š **åŒ¹é…ç²¾åº¦**: {success_count}/{len(test_cases)} = {accuracy:.1%}")

    if accuracy >= 0.8:
        print("ğŸ‰ è¯­ä¹‰åŒ¹é…è´¨é‡: ä¼˜ç§€!")
    elif accuracy >= 0.6:
        print("ğŸ‘ è¯­ä¹‰åŒ¹é…è´¨é‡: è‰¯å¥½")
    else:
        print("âš ï¸ è¯­ä¹‰åŒ¹é…è´¨é‡éœ€è¦æ”¹è¿›")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Phase 4ç»“æ„è¯†åˆ«ç³»ç»Ÿæµ‹è¯•")
    print("ğŸ¯ ç›®æ ‡: å°†Phase 2çš„å¹³é“ºå­—æ®µè½¬æ¢ä¸ºç»“æ„åŒ–åˆ†ç»„")
    print("âœ¨ ç‰¹è‰²: é…ç½®é©±åŠ¨çš„æ™ºèƒ½è¯­ä¹‰åŒ¹é…ï¼Œé¿å…ç¡¬ç¼–ç ")
    print()

    # æµ‹è¯•1: å®Œæ•´ç®¡é“æµ‹è¯•
    await test_phase4_complete_pipeline()

    # æµ‹è¯•2: è¯­ä¹‰åŒ¹é…å±•ç¤º
    await test_semantic_matching_showcase()

    print("\n" + "=" * 80)
    print("ğŸ‰ Phase 4æµ‹è¯•å®Œæˆ!")
    print("âœ¨ æ ¸å¿ƒæˆå°±:")
    print("   ğŸ“Š 31ä¸ªå¹³é“ºå­—æ®µ â†’ æ™ºèƒ½åˆ†ç»„")
    print("   ğŸ¯ 96.8%æ ‡ç­¾å…³è” â†’ è¯­ä¹‰åŒ¹é…")
    print("   ğŸ”§ é…ç½®é©±åŠ¨ â†’ æ— ç¡¬ç¼–ç ")
    print("   ğŸŒŸ æ¨¡ç³ŠåŒ¹é… â†’ æ”¯æŒå„ç§å˜ä½“")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())
